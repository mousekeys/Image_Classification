{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9097401,"sourceType":"datasetVersion","datasetId":5490352}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch-summary","metadata":{"execution":{"iopub.status.busy":"2024-08-08T10:50:06.575653Z","iopub.execute_input":"2024-08-08T10:50:06.576774Z","iopub.status.idle":"2024-08-08T10:50:18.784081Z","shell.execute_reply.started":"2024-08-08T10:50:06.576713Z","shell.execute_reply":"2024-08-08T10:50:18.782861Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch-summary in /opt/conda/lib/python3.10/site-packages (1.4.5)\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.utils.data as data\nfrom torchvision import datasets, transforms, models\nfrom torchvision.models.resnet import BasicBlock, ResNet\nimport numpy as np\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom torchsummary import summary","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-08T10:50:18.786225Z","iopub.execute_input":"2024-08-08T10:50:18.786562Z","iopub.status.idle":"2024-08-08T10:50:18.792755Z","shell.execute_reply.started":"2024-08-08T10:50:18.786531Z","shell.execute_reply":"2024-08-08T10:50:18.791860Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"class BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion * planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion * planes)\n            )\n\n    def forward(self, x):\n        out = torch.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = torch.relu(out)\n        return out\n\nclass CustomModel(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=25):\n        super(CustomModel, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.linear = nn.Linear(512 * block.expansion, num_classes)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1] * (num_blocks - 1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = torch.relu(self.bn1(self.conv1(x)))\n        out = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)(out)\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = nn.AdaptiveAvgPool2d((1, 1))(out)\n        out = torch.flatten(out, 1)\n        out = self.linear(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-08-08T10:58:06.309312Z","iopub.execute_input":"2024-08-08T10:58:06.309670Z","iopub.status.idle":"2024-08-08T10:58:06.325689Z","shell.execute_reply.started":"2024-08-08T10:58:06.309640Z","shell.execute_reply":"2024-08-08T10:58:06.324780Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"# take things to device the entire models things so thattheres no conflict between variables in devices\n\ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)     \n","metadata":{"execution":{"iopub.status.busy":"2024-08-08T10:58:00.650526Z","iopub.execute_input":"2024-08-08T10:58:00.651259Z","iopub.status.idle":"2024-08-08T10:58:00.656423Z","shell.execute_reply.started":"2024-08-08T10:58:00.651227Z","shell.execute_reply":"2024-08-08T10:58:00.655485Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"# Viem Model architecture\nfrom torchsummary import summary\nmodel = to_device(CustomModel(BasicBlock, [2, 2, 2, 2], num_classes=25),device)\nsummary(model)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-08T10:58:03.693414Z","iopub.execute_input":"2024-08-08T10:58:03.694313Z","iopub.status.idle":"2024-08-08T10:58:03.828843Z","shell.execute_reply.started":"2024-08-08T10:58:03.694275Z","shell.execute_reply":"2024-08-08T10:58:03.827974Z"},"trusted":true},"execution_count":84,"outputs":[{"name":"stdout","text":"=================================================================\nLayer (type:depth-idx)                   Param #\n=================================================================\n├─Conv2d: 1-1                            9,408\n├─BatchNorm2d: 1-2                       128\n├─Sequential: 1-3                        --\n|    └─BasicBlock: 2-1                   --\n|    |    └─Conv2d: 3-1                  36,864\n|    |    └─BatchNorm2d: 3-2             128\n|    |    └─Conv2d: 3-3                  36,864\n|    |    └─BatchNorm2d: 3-4             128\n|    |    └─Sequential: 3-5              --\n|    └─BasicBlock: 2-2                   --\n|    |    └─Conv2d: 3-6                  36,864\n|    |    └─BatchNorm2d: 3-7             128\n|    |    └─Conv2d: 3-8                  36,864\n|    |    └─BatchNorm2d: 3-9             128\n|    |    └─Sequential: 3-10             --\n├─Sequential: 1-4                        --\n|    └─BasicBlock: 2-3                   --\n|    |    └─Conv2d: 3-11                 73,728\n|    |    └─BatchNorm2d: 3-12            256\n|    |    └─Conv2d: 3-13                 147,456\n|    |    └─BatchNorm2d: 3-14            256\n|    |    └─Sequential: 3-15             8,448\n|    └─BasicBlock: 2-4                   --\n|    |    └─Conv2d: 3-16                 147,456\n|    |    └─BatchNorm2d: 3-17            256\n|    |    └─Conv2d: 3-18                 147,456\n|    |    └─BatchNorm2d: 3-19            256\n|    |    └─Sequential: 3-20             --\n├─Sequential: 1-5                        --\n|    └─BasicBlock: 2-5                   --\n|    |    └─Conv2d: 3-21                 294,912\n|    |    └─BatchNorm2d: 3-22            512\n|    |    └─Conv2d: 3-23                 589,824\n|    |    └─BatchNorm2d: 3-24            512\n|    |    └─Sequential: 3-25             33,280\n|    └─BasicBlock: 2-6                   --\n|    |    └─Conv2d: 3-26                 589,824\n|    |    └─BatchNorm2d: 3-27            512\n|    |    └─Conv2d: 3-28                 589,824\n|    |    └─BatchNorm2d: 3-29            512\n|    |    └─Sequential: 3-30             --\n├─Sequential: 1-6                        --\n|    └─BasicBlock: 2-7                   --\n|    |    └─Conv2d: 3-31                 1,179,648\n|    |    └─BatchNorm2d: 3-32            1,024\n|    |    └─Conv2d: 3-33                 2,359,296\n|    |    └─BatchNorm2d: 3-34            1,024\n|    |    └─Sequential: 3-35             132,096\n|    └─BasicBlock: 2-8                   --\n|    |    └─Conv2d: 3-36                 2,359,296\n|    |    └─BatchNorm2d: 3-37            1,024\n|    |    └─Conv2d: 3-38                 2,359,296\n|    |    └─BatchNorm2d: 3-39            1,024\n|    |    └─Sequential: 3-40             --\n├─Linear: 1-7                            12,825\n=================================================================\nTotal params: 11,189,337\nTrainable params: 11,189,337\nNon-trainable params: 0\n=================================================================\n","output_type":"stream"},{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"=================================================================\nLayer (type:depth-idx)                   Param #\n=================================================================\n├─Conv2d: 1-1                            9,408\n├─BatchNorm2d: 1-2                       128\n├─Sequential: 1-3                        --\n|    └─BasicBlock: 2-1                   --\n|    |    └─Conv2d: 3-1                  36,864\n|    |    └─BatchNorm2d: 3-2             128\n|    |    └─Conv2d: 3-3                  36,864\n|    |    └─BatchNorm2d: 3-4             128\n|    |    └─Sequential: 3-5              --\n|    └─BasicBlock: 2-2                   --\n|    |    └─Conv2d: 3-6                  36,864\n|    |    └─BatchNorm2d: 3-7             128\n|    |    └─Conv2d: 3-8                  36,864\n|    |    └─BatchNorm2d: 3-9             128\n|    |    └─Sequential: 3-10             --\n├─Sequential: 1-4                        --\n|    └─BasicBlock: 2-3                   --\n|    |    └─Conv2d: 3-11                 73,728\n|    |    └─BatchNorm2d: 3-12            256\n|    |    └─Conv2d: 3-13                 147,456\n|    |    └─BatchNorm2d: 3-14            256\n|    |    └─Sequential: 3-15             8,448\n|    └─BasicBlock: 2-4                   --\n|    |    └─Conv2d: 3-16                 147,456\n|    |    └─BatchNorm2d: 3-17            256\n|    |    └─Conv2d: 3-18                 147,456\n|    |    └─BatchNorm2d: 3-19            256\n|    |    └─Sequential: 3-20             --\n├─Sequential: 1-5                        --\n|    └─BasicBlock: 2-5                   --\n|    |    └─Conv2d: 3-21                 294,912\n|    |    └─BatchNorm2d: 3-22            512\n|    |    └─Conv2d: 3-23                 589,824\n|    |    └─BatchNorm2d: 3-24            512\n|    |    └─Sequential: 3-25             33,280\n|    └─BasicBlock: 2-6                   --\n|    |    └─Conv2d: 3-26                 589,824\n|    |    └─BatchNorm2d: 3-27            512\n|    |    └─Conv2d: 3-28                 589,824\n|    |    └─BatchNorm2d: 3-29            512\n|    |    └─Sequential: 3-30             --\n├─Sequential: 1-6                        --\n|    └─BasicBlock: 2-7                   --\n|    |    └─Conv2d: 3-31                 1,179,648\n|    |    └─BatchNorm2d: 3-32            1,024\n|    |    └─Conv2d: 3-33                 2,359,296\n|    |    └─BatchNorm2d: 3-34            1,024\n|    |    └─Sequential: 3-35             132,096\n|    └─BasicBlock: 2-8                   --\n|    |    └─Conv2d: 3-36                 2,359,296\n|    |    └─BatchNorm2d: 3-37            1,024\n|    |    └─Conv2d: 3-38                 2,359,296\n|    |    └─BatchNorm2d: 3-39            1,024\n|    |    └─Sequential: 3-40             --\n├─Linear: 1-7                            12,825\n=================================================================\nTotal params: 11,189,337\nTrainable params: 11,189,337\nNon-trainable params: 0\n================================================================="},"metadata":{}}]},{"cell_type":"code","source":"# Data augmentation and normalization for training\n# Just normalization for validation\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomRotation(30),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.4731, 0.4819, 0.4018], std=[0.1925, 0.1915, 0.1963])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.4706, 0.4802, 0.4020], std=[0.1907, 0.1898, 0.1950])\n    ]),\n}","metadata":{"execution":{"iopub.status.busy":"2024-08-08T10:58:09.972106Z","iopub.execute_input":"2024-08-08T10:58:09.972484Z","iopub.status.idle":"2024-08-08T10:58:09.980066Z","shell.execute_reply.started":"2024-08-08T10:58:09.972451Z","shell.execute_reply":"2024-08-08T10:58:09.979159Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"# Data loaded into the required part\n\ndata_dir = '/kaggle/input/seen-dataset-12-class/Seen Datasets'\nimage_datasets = {x: datasets.ImageFolder(root=f\"{data_dir}/{x}\", transform=data_transforms[x])\n                  for x in ['train', 'val']}\ndata_loaders = {x: data.DataLoader(image_datasets[x], batch_size=batch_size,\n                                   shuffle=True, num_workers=8, pin_memory=True)\n                for x in ['train', 'val']}\n\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\nclass_names = image_datasets['train'].classes\n","metadata":{"execution":{"iopub.status.busy":"2024-08-08T10:58:14.028519Z","iopub.execute_input":"2024-08-08T10:58:14.028990Z","iopub.status.idle":"2024-08-08T10:58:19.516582Z","shell.execute_reply.started":"2024-08-08T10:58:14.028958Z","shell.execute_reply":"2024-08-08T10:58:19.515790Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"# Loss and optimizer Intitalize\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.AdamW(model.parameters(), lr=initial_lr, weight_decay=weight_decay)\nscheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=initial_lr,steps_per_epoch=len(data_loaders['train']), epochs=num_epochs)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-08T10:58:22.725850Z","iopub.execute_input":"2024-08-08T10:58:22.726219Z","iopub.status.idle":"2024-08-08T10:58:22.733359Z","shell.execute_reply.started":"2024-08-08T10:58:22.726188Z","shell.execute_reply":"2024-08-08T10:58:22.732355Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"# Hyperparameters and Device Initialization \nnum_classes = 25\nbatch_size = 64\nnum_epochs = 50\ngrad_clip=0.1\ninitial_lr = 0.001\nweight_decay = 1e-4\ndropout_rate = 0.5\npatience = 10 \ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2024-08-08T10:58:25.309073Z","iopub.execute_input":"2024-08-08T10:58:25.309435Z","iopub.status.idle":"2024-08-08T10:58:25.315172Z","shell.execute_reply.started":"2024-08-08T10:58:25.309405Z","shell.execute_reply":"2024-08-08T10:58:25.314021Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"# Setup parameters required later for tracking \ntrain_loss_history = []\ntrain_acc_history = []\nval_loss_history = []\nval_acc_history = []\n\n# Training process not a fucntion\nbest_acc = 0.0\nearly_stop_counter = 0\nbest_model_wts = None\nfor epoch in range(num_epochs):\n    print(f'Epoch {epoch}/{num_epochs - 1}')\n\n    for phase in ['train', 'val']:\n        if phase == 'train':\n            model.train()\n        else:\n            model.eval()\n\n        running_loss = 0.0\n        running_corrects = 0\n\n        for inputs, labels in tqdm(data_loaders[phase], desc=f\"{phase} - Epoch {epoch+1}\"):\n            inputs = inputs.to(device, non_blocking=True) #Cuda or CPU\n            labels = labels.to(device, non_blocking=True)\n\n            optimizer.zero_grad()\n\n            with torch.set_grad_enabled(phase == 'train'):\n                outputs = model(inputs)\n                _, preds = torch.max(outputs, 1)\n                loss = criterion(outputs, labels)\n                \n#               Removed  \n#                 if grad_clip: \n#                     nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n\n                if phase == 'train':\n                    loss.backward()\n                    optimizer.step()\n\n            running_loss += loss.item() * inputs.size(0)\n            running_corrects += torch.sum(preds == labels.data)\n\n        if phase == 'train':\n            scheduler.step()\n            epoch_train_loss = running_loss / dataset_sizes['train']\n            epoch_train_corrects = running_corrects.double() / dataset_sizes['train']\n        else:\n            epoch_val_loss = running_loss / dataset_sizes['val']\n            epoch_val_corrects = running_corrects.double() / dataset_sizes['val']\n\n    train_loss_history.append(epoch_train_loss)\n    train_acc_history.append(epoch_train_corrects.item())\n    val_loss_history.append(epoch_val_loss)\n    val_acc_history.append(epoch_val_corrects.item())\n\n    print(f'Train Loss: {epoch_train_loss:.4f} Accuracy: {epoch_train_corrects:.4f}')\n    print(f'Validation Loss: {epoch_val_loss:.4f} Accuracy: {epoch_val_corrects:.4f}')\n\n    if epoch_val_corrects > best_acc:\n        best_acc = epoch_val_corrects\n        best_model_wts = model.state_dict().copy()\n        early_stop_counter = 0\n    else:\n        early_stop_counter += 1\n\n    if early_stop_counter >= patience:\n        print(\"Early stopping done\")\n        model.load_state_dict(best_model_wts)\n        break\n\nprint('Best Validation Accuracy: {:4f}'.format(best_acc))\n\n# Load best model weights\nif best_model_wts:\n    model.load_state_dict(best_model_wts)\n# Better if saved model each time we got better accuracy but takes too long time\n# Save the entire model\ntorch.save(model, 'resnet18_image_classify.pth')\nprint(\"Model saved\")","metadata":{"execution":{"iopub.status.busy":"2024-08-08T11:04:11.096792Z","iopub.execute_input":"2024-08-08T11:04:11.097151Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 0/49\n","output_type":"stream"},{"name":"stderr","text":"train - Epoch 1: 100%|██████████| 352/352 [02:37<00:00,  2.23it/s]\nval - Epoch 1: 100%|██████████| 118/118 [00:44<00:00,  2.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 2.4209 Accuracy: 0.2863\nValidation Loss: 2.1073 Accuracy: 0.3727\nEpoch 1/49\n","output_type":"stream"},{"name":"stderr","text":"train - Epoch 2: 100%|██████████| 352/352 [02:39<00:00,  2.21it/s]\nval - Epoch 2: 100%|██████████| 118/118 [00:45<00:00,  2.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 2.2422 Accuracy: 0.3363\nValidation Loss: 1.9708 Accuracy: 0.4159\nEpoch 2/49\n","output_type":"stream"},{"name":"stderr","text":"train - Epoch 3: 100%|██████████| 352/352 [02:36<00:00,  2.24it/s]\nval - Epoch 3: 100%|██████████| 118/118 [00:44<00:00,  2.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 2.1295 Accuracy: 0.3685\nValidation Loss: 1.6842 Accuracy: 0.4933\nEpoch 3/49\n","output_type":"stream"},{"name":"stderr","text":"train - Epoch 4: 100%|██████████| 352/352 [02:37<00:00,  2.24it/s]\nval - Epoch 4: 100%|██████████| 118/118 [00:44<00:00,  2.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.9976 Accuracy: 0.4052\nValidation Loss: 1.6017 Accuracy: 0.5213\nEpoch 4/49\n","output_type":"stream"},{"name":"stderr","text":"train - Epoch 5: 100%|██████████| 352/352 [02:37<00:00,  2.23it/s]\nval - Epoch 5: 100%|██████████| 118/118 [00:45<00:00,  2.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.9109 Accuracy: 0.4338\nValidation Loss: 1.4513 Accuracy: 0.5620\nEpoch 5/49\n","output_type":"stream"},{"name":"stderr","text":"train - Epoch 6: 100%|██████████| 352/352 [02:36<00:00,  2.26it/s]\nval - Epoch 6: 100%|██████████| 118/118 [00:44<00:00,  2.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.8087 Accuracy: 0.4618\nValidation Loss: 1.3132 Accuracy: 0.5956\nEpoch 6/49\n","output_type":"stream"},{"name":"stderr","text":"train - Epoch 7: 100%|██████████| 352/352 [02:37<00:00,  2.24it/s]\nval - Epoch 7: 100%|██████████| 118/118 [00:44<00:00,  2.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.7378 Accuracy: 0.4838\nValidation Loss: 1.3343 Accuracy: 0.5921\nEpoch 7/49\n","output_type":"stream"},{"name":"stderr","text":"train - Epoch 8: 100%|██████████| 352/352 [02:37<00:00,  2.23it/s]\nval - Epoch 8: 100%|██████████| 118/118 [00:44<00:00,  2.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.6841 Accuracy: 0.5012\nValidation Loss: 1.1567 Accuracy: 0.6495\nEpoch 8/49\n","output_type":"stream"},{"name":"stderr","text":"train - Epoch 9: 100%|██████████| 352/352 [02:33<00:00,  2.29it/s]\nval - Epoch 9: 100%|██████████| 118/118 [00:45<00:00,  2.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.6153 Accuracy: 0.5178\nValidation Loss: 1.1978 Accuracy: 0.6447\nEpoch 9/49\n","output_type":"stream"},{"name":"stderr","text":"train - Epoch 10: 100%|██████████| 352/352 [02:35<00:00,  2.27it/s]\nval - Epoch 10: 100%|██████████| 118/118 [00:44<00:00,  2.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.5690 Accuracy: 0.5339\nValidation Loss: 1.1333 Accuracy: 0.6604\nEpoch 10/49\n","output_type":"stream"},{"name":"stderr","text":"train - Epoch 11: 100%|██████████| 352/352 [02:33<00:00,  2.29it/s]\nval - Epoch 11: 100%|██████████| 118/118 [00:44<00:00,  2.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.5228 Accuracy: 0.5494\nValidation Loss: 0.9901 Accuracy: 0.7093\nEpoch 11/49\n","output_type":"stream"},{"name":"stderr","text":"train - Epoch 12: 100%|██████████| 352/352 [02:33<00:00,  2.29it/s]\nval - Epoch 12: 100%|██████████| 118/118 [00:44<00:00,  2.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.4738 Accuracy: 0.5612\nValidation Loss: 0.9057 Accuracy: 0.7252\nEpoch 12/49\n","output_type":"stream"},{"name":"stderr","text":"train - Epoch 13: 100%|██████████| 352/352 [02:33<00:00,  2.29it/s]\nval - Epoch 13: 100%|██████████| 118/118 [00:44<00:00,  2.64it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.4379 Accuracy: 0.5698\nValidation Loss: 0.9440 Accuracy: 0.7161\nEpoch 13/49\n","output_type":"stream"},{"name":"stderr","text":"train - Epoch 14: 100%|██████████| 352/352 [02:34<00:00,  2.27it/s]\nval - Epoch 14: 100%|██████████| 118/118 [00:44<00:00,  2.66it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.4065 Accuracy: 0.5804\nValidation Loss: 0.8841 Accuracy: 0.7339\nEpoch 14/49\n","output_type":"stream"},{"name":"stderr","text":"train - Epoch 15: 100%|██████████| 352/352 [02:35<00:00,  2.26it/s]\nval - Epoch 15: 100%|██████████| 118/118 [00:44<00:00,  2.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.3782 Accuracy: 0.5857\nValidation Loss: 0.8351 Accuracy: 0.7443\nEpoch 15/49\n","output_type":"stream"},{"name":"stderr","text":"train - Epoch 16: 100%|██████████| 352/352 [02:36<00:00,  2.25it/s]\nval - Epoch 16: 100%|██████████| 118/118 [00:44<00:00,  2.65it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.3374 Accuracy: 0.5997\nValidation Loss: 0.8884 Accuracy: 0.7381\nEpoch 16/49\n","output_type":"stream"},{"name":"stderr","text":"train - Epoch 17: 100%|██████████| 352/352 [02:40<00:00,  2.19it/s]\nval - Epoch 17: 100%|██████████| 118/118 [00:47<00:00,  2.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.3128 Accuracy: 0.6076\nValidation Loss: 0.7900 Accuracy: 0.7600\nEpoch 17/49\n","output_type":"stream"},{"name":"stderr","text":"train - Epoch 18: 100%|██████████| 352/352 [02:47<00:00,  2.10it/s]\nval - Epoch 18: 100%|██████████| 118/118 [00:48<00:00,  2.44it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.2849 Accuracy: 0.6203\nValidation Loss: 0.8310 Accuracy: 0.7425\nEpoch 18/49\n","output_type":"stream"},{"name":"stderr","text":"train - Epoch 19: 100%|██████████| 352/352 [02:45<00:00,  2.13it/s]\nval - Epoch 19: 100%|██████████| 118/118 [00:44<00:00,  2.63it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 1.2480 Accuracy: 0.6285\nValidation Loss: 0.7744 Accuracy: 0.7644\nEpoch 19/49\n","output_type":"stream"},{"name":"stderr","text":"train - Epoch 20:   5%|▍         | 16/352 [00:09<01:24,  3.96it/s]","output_type":"stream"}]},{"cell_type":"code","source":"# Plot the training curves\nepochs = len(train_loss_history)\n\nplt.figure(figsize=(12, 5))\n\n# Plot the loss\nplt.subplot(1, 2, 1)\nplt.plot(range(epochs), train_loss_history, label='Train Loss')\nplt.plot(range(epochs), val_loss_history, label='Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Losses')\nplt.title('Training and Validation Loss Graph')\nplt.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-08T10:55:14.229489Z","iopub.status.idle":"2024-08-08T10:55:14.229831Z","shell.execute_reply.started":"2024-08-08T10:55:14.229655Z","shell.execute_reply":"2024-08-08T10:55:14.229669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the accuracy\nplt.subplot(1, 2, 2)\nplt.plot(range(epochs), train_acc_history, label='Train Accuracy')\nplt.plot(range(epochs), val_acc_history, label='Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Training and Validation Accuracy Graph')\nplt.legend()\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]}]}