{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9097401,"sourceType":"datasetVersion","datasetId":5490352},{"sourceId":9119083,"sourceType":"datasetVersion","datasetId":5504670}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## EfficientNet Architecture","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nimport torchvision","metadata":{"execution":{"iopub.status.busy":"2024-08-08T13:12:55.259137Z","iopub.execute_input":"2024-08-08T13:12:55.260070Z","iopub.status.idle":"2024-08-08T13:12:55.264381Z","shell.execute_reply.started":"2024-08-08T13:12:55.260038Z","shell.execute_reply":"2024-08-08T13:12:55.263429Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"torch.cuda.manual_seed(42)\ntorch.manual_seed(42)","metadata":{"execution":{"iopub.status.busy":"2024-08-08T13:12:55.266262Z","iopub.execute_input":"2024-08-08T13:12:55.266632Z","iopub.status.idle":"2024-08-08T13:12:55.275263Z","shell.execute_reply.started":"2024-08-08T13:12:55.266607Z","shell.execute_reply":"2024-08-08T13:12:55.274380Z"},"trusted":true},"execution_count":77,"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7d6265b78e90>"},"metadata":{}}]},{"cell_type":"code","source":"class CNNBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride, groups=1,act=True, bias=False):\n        \n        super().__init__()\n        # same padding quick mapping:\n        # k=1 -> p =0, k=3 -> p=1, k=5 -> p=2\n        padding = kernel_size // 2\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding = padding, bias=bias, groups=groups)\n        self.batch_norm = nn.BatchNorm2d(out_channels)\n        self.activation = nn.SiLU() if act else nn.Identity()\n        \n    def forward(self, x):\n        x= self.conv(x)\n        x= self.batch_norm(x)\n        return self.activation(x)","metadata":{"execution":{"iopub.status.busy":"2024-08-08T13:12:55.276900Z","iopub.execute_input":"2024-08-08T13:12:55.277200Z","iopub.status.idle":"2024-08-08T13:12:55.285246Z","shell.execute_reply.started":"2024-08-08T13:12:55.277172Z","shell.execute_reply":"2024-08-08T13:12:55.284326Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"class SqueezeAndExcitationBlock(nn.Module):\n    def __init__(self, in_channels,reduction_ratio=16): #reduction_ratio to reduce computation, a hyperparameter. take r=16 for balance in complexity and capacity as in SeNet paper\n        super().__init__()\n        self.squeeze = nn.AdaptiveAvgPool2d((1,1))\n        self.fc1 = nn.Linear(in_channels , in_channels//reduction_ratio, bias=False)\n        self.relu = nn.ReLU(inplace=True)\n        self.fc2 = nn.Linear(in_channels//reduction_ratio, in_channels, bias =False)\n        self.sigmoid = nn.Sigmoid()\n        \n        \n    def forward(self,x):\n        \n        x_out = self.squeeze(x)\n        x_out = torch.flatten(x_out,1)\n        x_out = self.relu(self.fc1(x_out))\n        x_out = self.sigmoid(self.fc2(x_out))\n        \n        x_out = x_out[:,:,None,None]\n        \n        scaled = x * x_out\n        return scaled\n        ","metadata":{"execution":{"iopub.status.busy":"2024-08-08T13:12:55.286402Z","iopub.execute_input":"2024-08-08T13:12:55.286669Z","iopub.status.idle":"2024-08-08T13:12:55.296050Z","shell.execute_reply.started":"2024-08-08T13:12:55.286646Z","shell.execute_reply":"2024-08-08T13:12:55.295134Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"# class SqueezeAndExcitationBlockUncheckedLikelyWrong(nn.Module):\n#     def __init__(self, in_channels, reduction_ratio=16):\n#         super().__init__()\n#         self.squeeze = nn.AdaptiveAvgPool2d(1)\n#         self.excitation = nn.Sequential(\n#             nn.Linear(in_channels, in_channels // reduction_ratio, bias=False),\n#             nn.ReLU(inplace=True),\n#             nn.Linear(in_channels // reduction_ratio, in_channels, bias=False),\n#             nn.Sigmoid()\n#         )\n\n#     def forward(self, x):\n#         batch, channels, _, _ = x.size()\n#         y = self.squeeze(x).view(batch, channels)\n#         y = self.excitation(y).view(batch, channels, 1, 1)\n#         return x * y\n","metadata":{"execution":{"iopub.status.busy":"2024-08-08T13:12:55.298023Z","iopub.execute_input":"2024-08-08T13:12:55.298417Z","iopub.status.idle":"2024-08-08T13:12:55.303909Z","shell.execute_reply.started":"2024-08-08T13:12:55.298382Z","shell.execute_reply":"2024-08-08T13:12:55.303008Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"class MobileConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride, expansion_ratio, reduction_ratio):\n        super().__init__()\n        \n        exp_out_channels = in_channels * expansion_ratio\n        \n        #residual connection only when it is not being downsampled in any way\n        self.add_res = in_channels == out_channels and stride ==1\n        self.conv1 = CNNBlock(in_channels, exp_out_channels, 1,1) if expansion_ratio > 1 else nn.Identity()\n        \n        #depthwise convolution\n        self.conv2 = CNNBlock(exp_out_channels, exp_out_channels, kernel_size, stride, exp_out_channels)\n        self.se = SqueezeAndExcitationBlock(exp_out_channels,reduction_ratio)\n        self.conv3 = CNNBlock(exp_out_channels,out_channels, 1,1, act=False) #hatched line features means no activation\n        \n        self.sd = StochasticDepth(0.75)\n        \n    def forward(self, x):\n        x_out = self.conv3(self.se(self.conv2(self.conv1(x))))\n        \n        if self.add_res:\n            x_out = x + x_out\n        \n        x_out = self.sd(x_out)\n        \n        return x_out","metadata":{"execution":{"iopub.status.busy":"2024-08-08T13:12:55.304961Z","iopub.execute_input":"2024-08-08T13:12:55.305275Z","iopub.status.idle":"2024-08-08T13:12:55.314347Z","shell.execute_reply.started":"2024-08-08T13:12:55.305252Z","shell.execute_reply":"2024-08-08T13:12:55.313379Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"class ClassificationBlock(nn.Module):\n    def __init__(self,in_channels, n_classes, dropout_prob):\n        super().__init__()\n        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n        self.dropout = nn.Dropout(dropout_prob)\n        self.fc = nn.Linear(in_channels, n_classes)\n        self.sigmoid = nn.Sigmoid()\n        \n    def forward(self,x):\n        x = self.avgpool(x)\n        x = self.dropout(x)\n        x= torch.flatten(x,1)\n        x = self.fc(x)\n        return self.sigmoid(x)\n        ","metadata":{"execution":{"iopub.status.busy":"2024-08-08T13:12:55.416054Z","iopub.execute_input":"2024-08-08T13:12:55.416662Z","iopub.status.idle":"2024-08-08T13:12:55.423276Z","shell.execute_reply.started":"2024-08-08T13:12:55.416632Z","shell.execute_reply":"2024-08-08T13:12:55.422301Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"class StochasticDepth(nn.Module):\n    def __init__(self, p=0.75):\n        super().__init__()\n        self.p = p\n    \n    def forward(self, x):\n        \n        rand_mask = torch.rand((x.shape[0], 1,1,1),  dtype=x.dtype, device=x.device)\n        binary_mask = torch.floor(rand_mask) #TODO\n      \n        if self.training:   x = x/self.p * binary_mask\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2024-08-08T13:12:55.425188Z","iopub.execute_input":"2024-08-08T13:12:55.425721Z","iopub.status.idle":"2024-08-08T13:12:55.436020Z","shell.execute_reply.started":"2024-08-08T13:12:55.425693Z","shell.execute_reply":"2024-08-08T13:12:55.434954Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"class EffNet(nn.Module):\n    def __init__(self, model_name, in_channels=3, n_classes=25, show_output_dims=False):\n        super().__init__()\n        self.show = show_output_dims\n        self.model_name = model_name\n        self.config = Config()\n        self.stages = self.config.stages\n        self.phis = self.config.phis[model_name]\n        \n        #parameters\n        phi, res, dropout_p = self.phis\n        self.calc_coeffs(phi)\n        \n        #define network\n        self.network = nn.ModuleList([])\n        self.channels =[]\n        \n        #baseline stage 1\n        operator, channels, layers, kernel_size, stride, expansion_ratio = self.config.stages[0]\n        self.add_layers(3, operator, channels, layers, kernel_size, stride) #rgb input layer, TODO: check for errors\n        print(operator)\n        \n        #remaining stages: 9 stages ko 7 stages (2-8) lai\n        for i in range(1, len(self.stages)-1):\n           \n            if i==1:\n                reduction_ratio=4\n            else:\n                reduction_ratio=24\n                \n            operator, channels, layers, kernel_size, stride, expansion_ratio = self.config.stages[i]\n            self.add_layers(self.channels[-1], operator, channels, layers, kernel_size, stride, expansion_ratio, reduction_ratio)\n            print(operator)\n               \n\n        #final stage: conv1x1 and classifier\n        operator, channels, layers, kernel_size, stride, expansion_ratio = self.config.stages[-1]\n        self.add_layers(self.channels[-1], operator, channels, layers, kernel_size, stride) #the conv layer\n        print(operator)\n        self.network.append(ClassificationBlock(self.channels[-1], n_classes,dropout_p)) #the classifier block\n\n        \n    \n    def forward(self, x):\n        \n        for stage_num,module in enumerate(self.network):\n            \n            x= module(x)\n\n            shape = x.shape\n            if self.show: print(f\"shape of stage{stage_num} : {shape}\")\n                \n        return x\n    \n    \n    def add_layers(self, in_channels, operator, channels, layers, kernel_size, stride, *args):\n        \n        channels, layers = self.update_dw(channels, layers)\n        \n        if layers == 1:\n            self.network.append(operator(in_channels, channels, kernel_size, stride, *args))\n        else:\n            #the first \n            self.network.append(operator(in_channels, channels, kernel_size, 1, *args))\n            \n            #the remaining except first and last: works if there are >3 layers\n            for _ in range(layers-2):\n                self.network.append(operator(channels, channels,kernel_size, 1, *args))\n            \n            #final layer with stride dependent on the stage\n            self.network.append(operator(channels,channels, kernel_size, stride, *args))\n        \n        self.channels.append(channels)\n\n    # for models higher than the basseline:\n    \n    def calc_coeffs(self, phi, alpha=1.2, beta =1.1): #alpha and beta from EffNet paper, calculated through grid search. We dont use gamma but use the resolution from config\n        # in every higher model, the channels is multiplied by width (beta^phi) layers is multiplied by depth (alpha^phi)\n        self.depth = alpha ** phi\n        self.width = beta ** phi\n    \n    def update_dw(self,channels, layers):\n        return int(channels * self.width), int(layers * self.depth)\n        \n        ","metadata":{"execution":{"iopub.status.busy":"2024-08-08T13:12:55.438246Z","iopub.execute_input":"2024-08-08T13:12:55.438621Z","iopub.status.idle":"2024-08-08T13:12:55.458864Z","shell.execute_reply.started":"2024-08-08T13:12:55.438590Z","shell.execute_reply":"2024-08-08T13:12:55.457800Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"class Config:\n    stages = [\n            # [Operator(F), Channels, Layers, Kernel, Stride, Expansion Ratio]\n            [CNNBlock, 32, 1, 3, 2, 1], \n            [MobileConvBlock, 16, 1, 3, 1, 1],\n            [MobileConvBlock, 24, 2, 3, 2, 6],\n            [MobileConvBlock, 40, 2, 5, 2, 6],\n            [MobileConvBlock, 80, 3, 3, 2, 6],\n            [MobileConvBlock, 112, 3, 5, 1, 6],\n            [MobileConvBlock, 192, 4, 5, 2, 6],\n            [MobileConvBlock, 320, 1, 3, 1, 6],\n            [CNNBlock, 1280, 1, 1, 1, 0]\n    ]\n\n    phis = {\n            # BX : (phi, resolution, dropout) \n            \"B0\" : (0, 224, 0.2),\n            \"B1\" : (0.5, 240, 0.2),\n            \"B2\" : (1, 260, 0.3),\n            \"B3\" : (2, 300, 0.3),\n            \"B4\" : (3, 380, 0.4),\n            \"B5\" : (4, 456, 0.4),\n            \"B6\" : (5, 528, 0.5),\n            \"B7\" : (6, 600, 0.5)\n    }","metadata":{"execution":{"iopub.status.busy":"2024-08-08T13:12:55.460196Z","iopub.execute_input":"2024-08-08T13:12:55.460578Z","iopub.status.idle":"2024-08-08T13:12:55.470382Z","shell.execute_reply.started":"2024-08-08T13:12:55.460544Z","shell.execute_reply":"2024-08-08T13:12:55.469579Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel_name =\"B0\"\nmodel = EffNet(model_name = model_name, in_channels = 3, n_classes = 25, show_output_dims=False).to(device)\nres = Config().phis[model_name][1]\nprint(res)\n\nx= torch.randn((5, 3, res, res)).to(device)\nout= model(x)\nprint(out.shape)","metadata":{"execution":{"iopub.status.busy":"2024-08-08T13:12:55.472883Z","iopub.execute_input":"2024-08-08T13:12:55.473320Z","iopub.status.idle":"2024-08-08T13:12:55.589970Z","shell.execute_reply.started":"2024-08-08T13:12:55.473288Z","shell.execute_reply":"2024-08-08T13:12:55.588443Z"},"trusted":true},"execution_count":86,"outputs":[{"name":"stdout","text":"<class '__main__.CNNBlock'>\n<class '__main__.MobileConvBlock'>\n<class '__main__.MobileConvBlock'>\n<class '__main__.MobileConvBlock'>\n<class '__main__.MobileConvBlock'>\n<class '__main__.MobileConvBlock'>\n<class '__main__.MobileConvBlock'>\n<class '__main__.MobileConvBlock'>\n<class '__main__.CNNBlock'>\n224\ntorch.Size([5, 25])\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install torch-summary","metadata":{"execution":{"iopub.status.busy":"2024-08-08T13:12:55.591309Z","iopub.execute_input":"2024-08-08T13:12:55.591706Z","iopub.status.idle":"2024-08-08T13:13:08.088465Z","shell.execute_reply.started":"2024-08-08T13:12:55.591664Z","shell.execute_reply":"2024-08-08T13:13:08.087282Z"},"trusted":true},"execution_count":87,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch-summary in /opt/conda/lib/python3.10/site-packages (1.4.5)\n","output_type":"stream"}]},{"cell_type":"code","source":"from torchsummary import summary","metadata":{"execution":{"iopub.status.busy":"2024-08-08T13:13:08.090219Z","iopub.execute_input":"2024-08-08T13:13:08.091111Z","iopub.status.idle":"2024-08-08T13:13:08.095804Z","shell.execute_reply.started":"2024-08-08T13:13:08.091066Z","shell.execute_reply":"2024-08-08T13:13:08.094893Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"_ =summary(model,x)","metadata":{"execution":{"iopub.status.busy":"2024-08-08T13:13:08.097171Z","iopub.execute_input":"2024-08-08T13:13:08.097451Z","iopub.status.idle":"2024-08-08T13:13:08.370033Z","shell.execute_reply.started":"2024-08-08T13:13:08.097428Z","shell.execute_reply":"2024-08-08T13:13:08.369153Z"},"trusted":true},"execution_count":89,"outputs":[{"name":"stdout","text":"====================================================================================================\nLayer (type:depth-idx)                             Output Shape              Param #\n====================================================================================================\n├─ModuleList: 1                                    []                        --\n|    └─CNNBlock: 2-1                               [-1, 32, 112, 112]        --\n|    |    └─Conv2d: 3-1                            [-1, 32, 112, 112]        864\n|    |    └─BatchNorm2d: 3-2                       [-1, 32, 112, 112]        64\n|    |    └─SiLU: 3-3                              [-1, 32, 112, 112]        --\n|    └─MobileConvBlock: 2-2                        [-1, 16, 112, 112]        --\n|    |    └─Identity: 3-4                          [-1, 32, 112, 112]        --\n|    |    └─CNNBlock: 3-5                          [-1, 32, 112, 112]        352\n|    |    └─SqueezeAndExcitationBlock: 3-6         [-1, 32, 112, 112]        512\n|    |    └─CNNBlock: 3-7                          [-1, 16, 112, 112]        544\n|    |    └─StochasticDepth: 3-8                   [-1, 16, 112, 112]        --\n|    └─MobileConvBlock: 2-3                        [-1, 24, 112, 112]        --\n|    |    └─CNNBlock: 3-9                          [-1, 96, 112, 112]        1,728\n|    |    └─CNNBlock: 3-10                         [-1, 96, 112, 112]        1,056\n|    |    └─SqueezeAndExcitationBlock: 3-11        [-1, 96, 112, 112]        768\n|    |    └─CNNBlock: 3-12                         [-1, 24, 112, 112]        2,352\n|    |    └─StochasticDepth: 3-13                  [-1, 24, 112, 112]        --\n|    └─MobileConvBlock: 2-4                        [-1, 24, 56, 56]          --\n|    |    └─CNNBlock: 3-14                         [-1, 144, 112, 112]       3,744\n|    |    └─CNNBlock: 3-15                         [-1, 144, 56, 56]         1,584\n|    |    └─SqueezeAndExcitationBlock: 3-16        [-1, 144, 56, 56]         1,728\n|    |    └─CNNBlock: 3-17                         [-1, 24, 56, 56]          3,504\n|    |    └─StochasticDepth: 3-18                  [-1, 24, 56, 56]          --\n|    └─MobileConvBlock: 2-5                        [-1, 40, 56, 56]          --\n|    |    └─CNNBlock: 3-19                         [-1, 144, 56, 56]         3,744\n|    |    └─CNNBlock: 3-20                         [-1, 144, 56, 56]         3,888\n|    |    └─SqueezeAndExcitationBlock: 3-21        [-1, 144, 56, 56]         1,728\n|    |    └─CNNBlock: 3-22                         [-1, 40, 56, 56]          5,840\n|    |    └─StochasticDepth: 3-23                  [-1, 40, 56, 56]          --\n|    └─MobileConvBlock: 2-6                        [-1, 40, 28, 28]          --\n|    |    └─CNNBlock: 3-24                         [-1, 240, 56, 56]         10,080\n|    |    └─CNNBlock: 3-25                         [-1, 240, 28, 28]         6,480\n|    |    └─SqueezeAndExcitationBlock: 3-26        [-1, 240, 28, 28]         4,800\n|    |    └─CNNBlock: 3-27                         [-1, 40, 28, 28]          9,680\n|    |    └─StochasticDepth: 3-28                  [-1, 40, 28, 28]          --\n|    └─MobileConvBlock: 2-7                        [-1, 80, 28, 28]          --\n|    |    └─CNNBlock: 3-29                         [-1, 240, 28, 28]         10,080\n|    |    └─CNNBlock: 3-30                         [-1, 240, 28, 28]         2,640\n|    |    └─SqueezeAndExcitationBlock: 3-31        [-1, 240, 28, 28]         4,800\n|    |    └─CNNBlock: 3-32                         [-1, 80, 28, 28]          19,360\n|    |    └─StochasticDepth: 3-33                  [-1, 80, 28, 28]          --\n|    └─MobileConvBlock: 2-8                        [-1, 80, 28, 28]          --\n|    |    └─CNNBlock: 3-34                         [-1, 480, 28, 28]         39,360\n|    |    └─CNNBlock: 3-35                         [-1, 480, 28, 28]         5,280\n|    |    └─SqueezeAndExcitationBlock: 3-36        [-1, 480, 28, 28]         19,200\n|    |    └─CNNBlock: 3-37                         [-1, 80, 28, 28]          38,560\n|    |    └─StochasticDepth: 3-38                  [-1, 80, 28, 28]          --\n|    └─MobileConvBlock: 2-9                        [-1, 80, 14, 14]          --\n|    |    └─CNNBlock: 3-39                         [-1, 480, 28, 28]         39,360\n|    |    └─CNNBlock: 3-40                         [-1, 480, 14, 14]         5,280\n|    |    └─SqueezeAndExcitationBlock: 3-41        [-1, 480, 14, 14]         19,200\n|    |    └─CNNBlock: 3-42                         [-1, 80, 14, 14]          38,560\n|    |    └─StochasticDepth: 3-43                  [-1, 80, 14, 14]          --\n|    └─MobileConvBlock: 2-10                       [-1, 112, 14, 14]         --\n|    |    └─CNNBlock: 3-44                         [-1, 480, 14, 14]         39,360\n|    |    └─CNNBlock: 3-45                         [-1, 480, 14, 14]         12,960\n|    |    └─SqueezeAndExcitationBlock: 3-46        [-1, 480, 14, 14]         19,200\n|    |    └─CNNBlock: 3-47                         [-1, 112, 14, 14]         53,984\n|    |    └─StochasticDepth: 3-48                  [-1, 112, 14, 14]         --\n|    └─MobileConvBlock: 2-11                       [-1, 112, 14, 14]         --\n|    |    └─CNNBlock: 3-49                         [-1, 672, 14, 14]         76,608\n|    |    └─CNNBlock: 3-50                         [-1, 672, 14, 14]         18,144\n|    |    └─SqueezeAndExcitationBlock: 3-51        [-1, 672, 14, 14]         37,632\n|    |    └─CNNBlock: 3-52                         [-1, 112, 14, 14]         75,488\n|    |    └─StochasticDepth: 3-53                  [-1, 112, 14, 14]         --\n|    └─MobileConvBlock: 2-12                       [-1, 112, 14, 14]         --\n|    |    └─CNNBlock: 3-54                         [-1, 672, 14, 14]         76,608\n|    |    └─CNNBlock: 3-55                         [-1, 672, 14, 14]         18,144\n|    |    └─SqueezeAndExcitationBlock: 3-56        [-1, 672, 14, 14]         37,632\n|    |    └─CNNBlock: 3-57                         [-1, 112, 14, 14]         75,488\n|    |    └─StochasticDepth: 3-58                  [-1, 112, 14, 14]         --\n|    └─MobileConvBlock: 2-13                       [-1, 192, 14, 14]         --\n|    |    └─CNNBlock: 3-59                         [-1, 672, 14, 14]         76,608\n|    |    └─CNNBlock: 3-60                         [-1, 672, 14, 14]         18,144\n|    |    └─SqueezeAndExcitationBlock: 3-61        [-1, 672, 14, 14]         37,632\n|    |    └─CNNBlock: 3-62                         [-1, 192, 14, 14]         129,408\n|    |    └─StochasticDepth: 3-63                  [-1, 192, 14, 14]         --\n|    └─MobileConvBlock: 2-14                       [-1, 192, 14, 14]         --\n|    |    └─CNNBlock: 3-64                         [-1, 1152, 14, 14]        223,488\n|    |    └─CNNBlock: 3-65                         [-1, 1152, 14, 14]        31,104\n|    |    └─SqueezeAndExcitationBlock: 3-66        [-1, 1152, 14, 14]        110,592\n|    |    └─CNNBlock: 3-67                         [-1, 192, 14, 14]         221,568\n|    |    └─StochasticDepth: 3-68                  [-1, 192, 14, 14]         --\n|    └─MobileConvBlock: 2-15                       [-1, 192, 14, 14]         --\n|    |    └─CNNBlock: 3-69                         [-1, 1152, 14, 14]        223,488\n|    |    └─CNNBlock: 3-70                         [-1, 1152, 14, 14]        31,104\n|    |    └─SqueezeAndExcitationBlock: 3-71        [-1, 1152, 14, 14]        110,592\n|    |    └─CNNBlock: 3-72                         [-1, 192, 14, 14]         221,568\n|    |    └─StochasticDepth: 3-73                  [-1, 192, 14, 14]         --\n|    └─MobileConvBlock: 2-16                       [-1, 192, 7, 7]           --\n|    |    └─CNNBlock: 3-74                         [-1, 1152, 14, 14]        223,488\n|    |    └─CNNBlock: 3-75                         [-1, 1152, 7, 7]          31,104\n|    |    └─SqueezeAndExcitationBlock: 3-76        [-1, 1152, 7, 7]          110,592\n|    |    └─CNNBlock: 3-77                         [-1, 192, 7, 7]           221,568\n|    |    └─StochasticDepth: 3-78                  [-1, 192, 7, 7]           --\n|    └─MobileConvBlock: 2-17                       [-1, 320, 7, 7]           --\n|    |    └─CNNBlock: 3-79                         [-1, 1152, 7, 7]          223,488\n|    |    └─CNNBlock: 3-80                         [-1, 1152, 7, 7]          12,672\n|    |    └─SqueezeAndExcitationBlock: 3-81        [-1, 1152, 7, 7]          110,592\n|    |    └─CNNBlock: 3-82                         [-1, 320, 7, 7]           369,280\n|    |    └─StochasticDepth: 3-83                  [-1, 320, 7, 7]           --\n|    └─CNNBlock: 2-18                              [-1, 1280, 7, 7]          --\n|    |    └─Conv2d: 3-84                           [-1, 1280, 7, 7]          409,600\n|    |    └─BatchNorm2d: 3-85                      [-1, 1280, 7, 7]          2,560\n|    |    └─SiLU: 3-86                             [-1, 1280, 7, 7]          --\n|    └─ClassificationBlock: 2-19                   [-1, 25]                  --\n|    |    └─AdaptiveAvgPool2d: 3-87                [-1, 1280, 1, 1]          --\n|    |    └─Dropout: 3-88                          [-1, 1280, 1, 1]          --\n|    |    └─Linear: 3-89                           [-1, 25]                  32,025\n|    |    └─Sigmoid: 3-90                          [-1, 25]                  --\n====================================================================================================\nTotal params: 4,030,233\nTrainable params: 4,030,233\nNon-trainable params: 0\nTotal mult-adds (M): 774.39\n====================================================================================================\nInput size (MB): 2.87\nForward/backward pass size (MB): 188.22\nParams size (MB): 15.37\nEstimated Total Size (MB): 206.47\n====================================================================================================\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 2. Training, Validating and Saving the model","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets\nfrom torchvision.transforms import transforms, ToTensor\nfrom tqdm import tqdm\nfrom torchvision import models","metadata":{"execution":{"iopub.status.busy":"2024-08-08T13:13:08.373131Z","iopub.execute_input":"2024-08-08T13:13:08.373435Z","iopub.status.idle":"2024-08-08T13:13:08.379039Z","shell.execute_reply.started":"2024-08-08T13:13:08.373409Z","shell.execute_reply":"2024-08-08T13:13:08.377805Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"train_dir = \"/kaggle/input/seen-25-bird-dataset/Seen Datasets/train\"\nval_dir = \"/kaggle/input/seen-25-bird-dataset/Seen Datasets/val\"\ntest_dir =\"\"","metadata":{"execution":{"iopub.status.busy":"2024-08-08T13:13:08.380273Z","iopub.execute_input":"2024-08-08T13:13:08.380638Z","iopub.status.idle":"2024-08-08T13:13:08.386312Z","shell.execute_reply.started":"2024-08-08T13:13:08.380605Z","shell.execute_reply":"2024-08-08T13:13:08.385388Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"# #data loaders for mean calculation\n# transforms_func = transforms.Compose([transforms.Resize((224,224)),\n#                                       ToTensor()])\n# train_ds= datasets.ImageFolder(train_dir, transform=transforms_func)\n# batch_size = 32\n# train_dataloader = DataLoader(train_ds, batch_size=batch_size,shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-08T13:13:08.390006Z","iopub.execute_input":"2024-08-08T13:13:08.390353Z","iopub.status.idle":"2024-08-08T13:13:08.394491Z","shell.execute_reply.started":"2024-08-08T13:13:08.390329Z","shell.execute_reply":"2024-08-08T13:13:08.393483Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"# def get_ds_mean_std(dataloader):\n#     mean= 0.0 # torch.zeros(3)\n#     var= 0.0 # torch.zeros(3)\n#     n_imgs_total=0\n#     i=0\n#     for images, _ in dataloader:\n        \n#         n_imgs_per_batch = images.shape[0]\n# #         print(images)\n#         #b,c,w*h\n#         channelwise_images = images.view(n_imgs_per_batch, images.shape[1], -1)\n#         #mean and var per channel, summed every batch\n#         mean += channelwise_images.mean(2).sum(0)\n      \n#         var += channelwise_images.var(2).sum(0)\n       \n#         n_imgs_total += n_imgs_per_batch\n            \n#     #means can simply be averaged\n#     mean /=n_imgs_total\n\n#     #std can't be averaged. but, for equal batch sizes (only one batch might have different size)\n#     std = torch.sqrt(var/n_imgs_total)\n#     print(n_imgs_total)\n#     return mean,std\n        ","metadata":{"execution":{"iopub.status.busy":"2024-08-08T13:13:08.395675Z","iopub.execute_input":"2024-08-08T13:13:08.395935Z","iopub.status.idle":"2024-08-08T13:13:08.404213Z","shell.execute_reply.started":"2024-08-08T13:13:08.395912Z","shell.execute_reply":"2024-08-08T13:13:08.403462Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"# get_ds_mean_std(train_dataloader)","metadata":{"execution":{"iopub.status.busy":"2024-08-08T13:13:08.405231Z","iopub.execute_input":"2024-08-08T13:13:08.405567Z","iopub.status.idle":"2024-08-08T13:13:08.410927Z","shell.execute_reply.started":"2024-08-08T13:13:08.405521Z","shell.execute_reply":"2024-08-08T13:13:08.410040Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"#output of above\nds_mean, ds_std = [0.4731, 0.4819, 0.4018], [0.3544, 0.3544, 0.3544]","metadata":{"execution":{"iopub.status.busy":"2024-08-08T13:13:08.412072Z","iopub.execute_input":"2024-08-08T13:13:08.412353Z","iopub.status.idle":"2024-08-08T13:13:08.418341Z","shell.execute_reply.started":"2024-08-08T13:13:08.412321Z","shell.execute_reply":"2024-08-08T13:13:08.417482Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"transforms_func = transforms.Compose([transforms.Resize((416,416)),\n                                      transforms.RandomHorizontalFlip(),\n                                      transforms.RandomRotation(10),\n                                      ToTensor(),\n                                      transforms.Normalize(mean=ds_mean, std=ds_std)])\n\ntrain_ds= datasets.ImageFolder(train_dir, transform=transforms_func)\n# test_ds= datasets.ImageFolder(test_dir, transform=transforms_func)\nval_ds= datasets.ImageFolder(val_dir, transform=transforms_func)\n\n#data loaders for training\n\nbatchsize = 64\n\ntrain_dataloader = DataLoader(train_ds, batch_size=batchsize,shuffle=True, num_workers=4, pin_memory=True)\n# test_dataloader = DataLoader(test_ds, batch_size=batch_size,shuffle=False)\nval_dataloader = DataLoader(val_ds, batch_size=batchsize,shuffle=False,  num_workers=4, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-08T13:13:08.419450Z","iopub.execute_input":"2024-08-08T13:13:08.419748Z","iopub.status.idle":"2024-08-08T13:13:15.741437Z","shell.execute_reply.started":"2024-08-08T13:13:08.419714Z","shell.execute_reply":"2024-08-08T13:13:15.740389Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"len(train_ds), len(val_ds)","metadata":{"execution":{"iopub.status.busy":"2024-08-08T13:13:15.742683Z","iopub.execute_input":"2024-08-08T13:13:15.742986Z","iopub.status.idle":"2024-08-08T13:13:15.750161Z","shell.execute_reply.started":"2024-08-08T13:13:15.742960Z","shell.execute_reply":"2024-08-08T13:13:15.749065Z"},"trusted":true},"execution_count":97,"outputs":[{"execution_count":97,"output_type":"execute_result","data":{"text/plain":"(22500, 7500)"},"metadata":{}}]},{"cell_type":"markdown","source":"### Training Loop","metadata":{}},{"cell_type":"code","source":"optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001, alpha=0.9, momentum=0.9, weight_decay = 1e-5)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=2, eta_min=1e-5) \ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-08-08T13:13:15.751728Z","iopub.execute_input":"2024-08-08T13:13:15.752116Z","iopub.status.idle":"2024-08-08T13:13:15.760842Z","shell.execute_reply.started":"2024-08-08T13:13:15.752083Z","shell.execute_reply":"2024-08-08T13:13:15.760093Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"def get_lr(optimizer):\n    #list of param groups\n    return optimizer.param_groups[0][\"lr\"]\n    \n# def get_lr(optimizer):\n#     for param_group in optimizer.param_groups:\n#         return param_group[\"lr\"]\n\nprint(get_lr(optimizer))","metadata":{"execution":{"iopub.status.busy":"2024-08-08T13:13:15.761989Z","iopub.execute_input":"2024-08-08T13:13:15.762272Z","iopub.status.idle":"2024-08-08T13:13:15.768438Z","shell.execute_reply.started":"2024-08-08T13:13:15.762249Z","shell.execute_reply":"2024-08-08T13:13:15.767521Z"},"trusted":true},"execution_count":99,"outputs":[{"name":"stdout","text":"0.001\n","output_type":"stream"}]},{"cell_type":"code","source":"#calculate loss values per batch of data\n\ndef loss_batch(criterion, result, target, Training=True):\n    \n    #get loss\n    loss=criterion(result,target)\n    \n    \n    if Training is True:\n        #backward propagation\n        loss.backward()\n    \n    \n#     print(f\"batch loss:{loss} \")\n    #get performance metric\n#     print(f\"result: {result}\")\n#     print(f\"target: {target}\")\n#     n_correct_b = count_correct_batch(result,target)\n    \n#     print(f\"n_correct per batch: {n_correct_b}\")\n    \n    return loss.item()","metadata":{"execution":{"iopub.status.busy":"2024-08-08T13:13:15.769592Z","iopub.execute_input":"2024-08-08T13:13:15.770165Z","iopub.status.idle":"2024-08-08T13:13:15.776268Z","shell.execute_reply.started":"2024-08-08T13:13:15.770133Z","shell.execute_reply":"2024-08-08T13:13:15.775390Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-08-08T13:13:15.777191Z","iopub.execute_input":"2024-08-08T13:13:15.777771Z","iopub.status.idle":"2024-08-08T13:13:15.784196Z","shell.execute_reply.started":"2024-08-08T13:13:15.777739Z","shell.execute_reply":"2024-08-08T13:13:15.783314Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"def display_batch(batch):\n  \"\"\"Displays images in a batch.\n  Args:\n    batch: A batch of images, either as a NumPy array or PyTorch tensor.\n  \"\"\"\n\n  # Convert to NumPy array if necessary\n  if isinstance(batch, torch.Tensor):\n    batch = batch.numpy()\n\n  # Assuming images are in CHW format, convert to HWC for display\n  batch = np.transpose(batch, (0, 2, 3, 1))\n\n  # Calculate the number of rows and columns for the grid\n  num_images = batch.shape[0]\n  cols = min(8, num_images)\n  rows = (num_images + cols - 1) // cols\n\n  # Create a figure and subplots\n  fig, axes = plt.subplots(rows, cols, figsize=(cols * 3, rows * 3))\n\n  # Iterate over images and display them\n  for i in range(num_images):\n    ax = axes.flatten()[i]\n    ax.imshow(batch[i])\n    ax.axis('off')\n\n  plt.tight_layout()\n  plt.show()\n","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2024-08-08T13:13:15.785306Z","iopub.execute_input":"2024-08-08T13:13:15.785737Z","iopub.status.idle":"2024-08-08T13:13:15.793582Z","shell.execute_reply.started":"2024-08-08T13:13:15.785707Z","shell.execute_reply":"2024-08-08T13:13:15.792600Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"def loss_acc_epoch(model, criterion, dataloader,is_train, check_id=False, optimizer=None):\n    \n    epoch_loss =0.0\n    epoch_acc =0.0\n    batch_number =0\n    \n    for images, labels in tqdm(dataloader):\n        \n        \n#         if batch_number % 100 ==0:\n#             display_batch(images)\n        \n        images = images.to(device)\n        labels = labels.to(device)\n        \n        result = model(images)\n        \n        if optimizer is not None:\n            # zero the gradient of optimizer\n            optimizer.zero_grad()\n            \n            loss_b = loss_batch(criterion,result,labels,Training=True)\n            \n            #step optimizer\n            optimizer.step()\n        else:\n            loss_b = loss_batch(criterion,result,labels,Training=False)\n            \n        \n        batch_number += 1\n        epoch_loss += loss_b\n        epoch_acc += torch.sum(result.argmax(dim=1).round() == labels.float()).item()\n        \n    \n    loss_epoch = epoch_loss/batch_number\n    acc_epoch = epoch_acc/len(dataloader.dataset)\n    \n    return loss_epoch, acc_epoch\n    ","metadata":{"execution":{"iopub.status.busy":"2024-08-08T13:13:15.794894Z","iopub.execute_input":"2024-08-08T13:13:15.795629Z","iopub.status.idle":"2024-08-08T13:13:15.803966Z","shell.execute_reply.started":"2024-08-08T13:13:15.795597Z","shell.execute_reply":"2024-08-08T13:13:15.803134Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"import copy","metadata":{"execution":{"iopub.status.busy":"2024-08-08T13:13:15.805144Z","iopub.execute_input":"2024-08-08T13:13:15.805384Z","iopub.status.idle":"2024-08-08T13:13:15.811096Z","shell.execute_reply.started":"2024-08-08T13:13:15.805363Z","shell.execute_reply":"2024-08-08T13:13:15.810319Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"def train(model,train_dataloader, val_dataloader, criterion, optimizer, n_epochs, device, scheduler,check_id, save_path, val_iter):\n    \n    loss_hist = {\n        \"train\": [],\n        \"val\": []\n    }\n    \n    acc_hist={\n        \"train\": [],\n        \"val\": []\n    }\n    \n    \n#     #copy the current model wts as best model:\n#     best_model_wts = copy.deepcopy(model.state_dict())\n#     best_loss=float('inf')\n#     #TODO:\n    \n    for epoch in range(n_epochs):\n        \n\n        print(f\"Epoch {epoch+1} of {n_epochs}\")\n        current_lr = get_lr(optimizer)\n        \n        print(\"training\")\n        model.train()\n        train_loss_epoch, train_acc_epoch = loss_acc_epoch(model, criterion, train_dataloader,True, check_id, optimizer)\n        \n        loss_hist[\"train\"].append(train_loss_epoch)\n        acc_hist[\"train\"].append(train_acc_epoch)\n        print(f\"Tr.Loss: {train_loss_epoch:.5f}, Tr.Acc:{train_acc_epoch:.5f}\")\n        #validating now\n        print(\"validation\")\n        model.eval()\n        with torch.no_grad():\n            val_loss_epoch, val_acc_epoch = loss_acc_epoch(model,criterion, val_dataloader, False, check_id)\n            loss_hist[\"val\"].append(val_loss_epoch)\n            acc_hist[\"val\"].append(val_acc_epoch)\n        \n#         #every epoch, keep on selecting the best model sofar\n#         if val_loss_epoch < best_loss:\n#             best_loss = val_loss_epoch\n#             best_model_wts = copy.deepcopy(model.state_dict())\n            \n#             torch.save(model.state_dict(), \"savemodel.pt\")\n#             print(\"best model saved\")\n            \n        scheduler.step()\n        print(f\"Val.loss: {val_loss_epoch}, Val.Acc: {val_acc_epoch:.5f} \")\n        \n        \n    return loss_hist, acc_hist","metadata":{"execution":{"iopub.status.busy":"2024-08-08T13:13:15.812192Z","iopub.execute_input":"2024-08-08T13:13:15.812457Z","iopub.status.idle":"2024-08-08T13:13:15.821894Z","shell.execute_reply.started":"2024-08-08T13:13:15.812436Z","shell.execute_reply":"2024-08-08T13:13:15.821110Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"save_path = \"/kaggle/working/\"","metadata":{"execution":{"iopub.status.busy":"2024-08-08T13:13:15.822916Z","iopub.execute_input":"2024-08-08T13:13:15.823210Z","iopub.status.idle":"2024-08-08T13:13:15.831961Z","shell.execute_reply.started":"2024-08-08T13:13:15.823187Z","shell.execute_reply":"2024-08-08T13:13:15.831036Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"# model2 = models.efficientnet_b5(pretrained=False)\n\n# # Modify the classifier to have 6 output classes instead of 1000\n# model2.classifier[1] = nn.Linear(model2.classifier[1].in_features, 25)\n\n# def initialize_weights(m):\n#     if isinstance(m, nn.Conv2d):\n#         nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n#         if m.bias is not None:\n#             nn.init.constant_(m.bias, 0)\n#     elif isinstance(m, nn.BatchNorm2d):\n#         nn.init.constant_(m.weight, 1)\n#         nn.init.constant_(m.bias, 0)\n#     elif isinstance(m, nn.Linear):\n#         nn.init.normal_(m.weight, 0, 0.01)\n#         nn.init.constant_(m.bias, 0)\n\n# # Apply the weight initialization\n# model2.apply(initialize_weights)\n# model2.to(device)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-08T13:13:15.833188Z","iopub.execute_input":"2024-08-08T13:13:15.833922Z","iopub.status.idle":"2024-08-08T13:13:15.839306Z","shell.execute_reply.started":"2024-08-08T13:13:15.833891Z","shell.execute_reply":"2024-08-08T13:13:15.838582Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"\n    \nclass AlexNet(nn.Module):\n    def __init__(self, num_classes=25):\n        super().__init__()\n        self.features_extraction = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),  \n            nn.ReLU(inplace=True),\n            nn.BatchNorm2d(64),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n              \n            \n            nn.Conv2d(64, 192, kernel_size=5, padding=2),  \n            nn.ReLU(inplace=True),\n            nn.BatchNorm2d(192),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            \n            \n            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm2d(384),\n            \n            nn.Conv2d(384, 256, kernel_size=3, padding=1),  \n            nn.ReLU(inplace=True),\n            nn.BatchNorm2d(256),\n            \n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm2d(256),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.AdaptiveAvgPool2d((6, 6)),  \n        )\n        self.classifier = nn.Sequential(\n            nn.Dropout(0.1),\n            nn.Linear(256 * 6 * 6, 4096),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm1d(4096),\n            \n            nn.Dropout(0.1),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm1d(4096),\n            \n            nn.Dropout(0.1),\n            nn.Linear(4096, 512),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm1d(512),\n            \n            nn.Linear(512, num_classes),\n        )\n\n    def forward(self, x):\n        x = self.features_extraction(x)\n        x = x.view(x.size(0), -1)\n        return self.classifier(x)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-08-08T13:13:15.840341Z","iopub.execute_input":"2024-08-08T13:13:15.840632Z","iopub.status.idle":"2024-08-08T13:13:15.853523Z","shell.execute_reply.started":"2024-08-08T13:13:15.840609Z","shell.execute_reply":"2024-08-08T13:13:15.852565Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"model=AlexNet()","metadata":{"execution":{"iopub.status.busy":"2024-08-08T13:13:15.854756Z","iopub.execute_input":"2024-08-08T13:13:15.855028Z","iopub.status.idle":"2024-08-08T13:13:16.436518Z","shell.execute_reply.started":"2024-08-08T13:13:15.855005Z","shell.execute_reply":"2024-08-08T13:13:16.435488Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"model = model.to(device)\nmodel = nn.DataParallel(model,device_ids =[0,1]) # to use multiple gpu\nn_epochs = 10\n\n#scheduler ni chaine ho? for lr decay. edit: Hola, lets see. TODO: copy paper's\noptimizer = torch.optim.RMSprop(model.parameters(), lr=0.001, alpha=0.9, momentum=0.9, weight_decay = 1e-5)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=2, eta_min=1e-5) \ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-08-08T13:13:16.441130Z","iopub.execute_input":"2024-08-08T13:13:16.441782Z","iopub.status.idle":"2024-08-08T13:13:16.516381Z","shell.execute_reply.started":"2024-08-08T13:13:16.441753Z","shell.execute_reply":"2024-08-08T13:13:16.515426Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"loss_hist, acc_hist = train(model,train_dataloader, val_dataloader, criterion, optimizer, n_epochs, device=device, scheduler=scheduler,check_id=False, save_path=save_path, val_iter=1)","metadata":{"execution":{"iopub.status.busy":"2024-08-08T13:13:16.517583Z","iopub.execute_input":"2024-08-08T13:13:16.517930Z","iopub.status.idle":"2024-08-08T13:54:57.954987Z","shell.execute_reply.started":"2024-08-08T13:13:16.517894Z","shell.execute_reply":"2024-08-08T13:54:57.953888Z"},"trusted":true},"execution_count":111,"outputs":[{"name":"stdout","text":"Epoch 1 of 10\ntraining\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 352/352 [03:13<00:00,  1.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Tr.Loss: 2.99018, Tr.Acc:0.14316\nvalidation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 118/118 [01:02<00:00,  1.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val.loss: 2.656839860697924, Val.Acc: 0.18160 \nEpoch 2 of 10\ntraining\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 352/352 [03:08<00:00,  1.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Tr.Loss: 2.17072, Tr.Acc:0.30724\nvalidation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 118/118 [01:01<00:00,  1.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val.loss: 2.0110171730235473, Val.Acc: 0.35213 \nEpoch 3 of 10\ntraining\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 352/352 [03:08<00:00,  1.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Tr.Loss: 1.83413, Tr.Acc:0.41551\nvalidation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 118/118 [01:01<00:00,  1.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val.loss: 1.7553924109976171, Val.Acc: 0.44467 \nEpoch 4 of 10\ntraining\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 352/352 [03:08<00:00,  1.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Tr.Loss: 1.81243, Tr.Acc:0.42907\nvalidation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 118/118 [01:01<00:00,  1.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val.loss: 1.7256363721217138, Val.Acc: 0.46360 \nEpoch 5 of 10\ntraining\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 352/352 [03:08<00:00,  1.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Tr.Loss: 1.67053, Tr.Acc:0.48893\nvalidation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 118/118 [01:02<00:00,  1.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val.loss: 1.8073886521792009, Val.Acc: 0.49347 \nEpoch 6 of 10\ntraining\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 352/352 [03:08<00:00,  1.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Tr.Loss: 1.19196, Tr.Acc:0.63658\nvalidation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 118/118 [01:01<00:00,  1.92it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val.loss: 1.1205631042436017, Val.Acc: 0.66480 \nEpoch 7 of 10\ntraining\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 352/352 [03:07<00:00,  1.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Tr.Loss: 0.91888, Tr.Acc:0.72053\nvalidation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 118/118 [01:00<00:00,  1.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val.loss: 0.8586647944935297, Val.Acc: 0.73920 \nEpoch 8 of 10\ntraining\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 352/352 [03:09<00:00,  1.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Tr.Loss: 0.99886, Tr.Acc:0.69667\nvalidation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 118/118 [01:01<00:00,  1.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val.loss: 0.99547142156605, Val.Acc: 0.69853 \nEpoch 9 of 10\ntraining\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 352/352 [03:07<00:00,  1.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Tr.Loss: 1.10118, Tr.Acc:0.66733\nvalidation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 118/118 [01:00<00:00,  1.94it/s]\n","output_type":"stream"},{"name":"stdout","text":"Val.loss: 1.2087937669228699, Val.Acc: 0.64173 \nEpoch 10 of 10\ntraining\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 352/352 [03:07<00:00,  1.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"Tr.Loss: 0.80696, Tr.Acc:0.75756\nvalidation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 118/118 [01:00<00:00,  1.94it/s]","output_type":"stream"},{"name":"stdout","text":"Val.loss: 0.8227307216848357, Val.Acc: 0.75707 \n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"checkpoint = {\n    'model_state_dict': model.state_dict(),\n    'optimizer_state_dict': optimizer.state_dict(),\n    'loss_hist': loss_hist,\n    'accuracy_hist': acc_hist,\n}\n\ntorch.save(checkpoint, '/kaggle/working/checkpoint.pth')","metadata":{"execution":{"iopub.status.busy":"2024-08-08T14:37:55.072450Z","iopub.execute_input":"2024-08-08T14:37:55.072848Z","iopub.status.idle":"2024-08-08T14:37:57.167820Z","shell.execute_reply.started":"2024-08-08T14:37:55.072820Z","shell.execute_reply":"2024-08-08T14:37:57.166696Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"test_model =AlexNet()","metadata":{"execution":{"iopub.status.busy":"2024-08-08T14:37:57.170119Z","iopub.execute_input":"2024-08-08T14:37:57.170722Z","iopub.status.idle":"2024-08-08T14:37:57.789714Z","shell.execute_reply.started":"2024-08-08T14:37:57.170691Z","shell.execute_reply":"2024-08-08T14:37:57.788817Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"# Move the model to GPU if available\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ntest_model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-08T14:37:57.791013Z","iopub.execute_input":"2024-08-08T14:37:57.791356Z","iopub.status.idle":"2024-08-08T14:37:57.871229Z","shell.execute_reply.started":"2024-08-08T14:37:57.791326Z","shell.execute_reply":"2024-08-08T14:37:57.870257Z"},"trusted":true},"execution_count":129,"outputs":[{"execution_count":129,"output_type":"execute_result","data":{"text/plain":"AlexNet(\n  (features_extraction): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n    (1): ReLU(inplace=True)\n    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (4): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (5): ReLU(inplace=True)\n    (6): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (7): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (8): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (9): ReLU(inplace=True)\n    (10): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (11): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (12): ReLU(inplace=True)\n    (13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (15): ReLU(inplace=True)\n    (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (17): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (18): AdaptiveAvgPool2d(output_size=(6, 6))\n  )\n  (classifier): Sequential(\n    (0): Dropout(p=0.1, inplace=False)\n    (1): Linear(in_features=9216, out_features=4096, bias=True)\n    (2): ReLU(inplace=True)\n    (3): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (4): Dropout(p=0.1, inplace=False)\n    (5): Linear(in_features=4096, out_features=4096, bias=True)\n    (6): ReLU(inplace=True)\n    (7): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (8): Dropout(p=0.1, inplace=False)\n    (9): Linear(in_features=4096, out_features=512, bias=True)\n    (10): ReLU(inplace=True)\n    (11): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (12): Linear(in_features=512, out_features=25, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Example of loading a checkpoint and extracting loss and accuracy history\ncheckpoint_path = '/kaggle/working/checkpoint.pth'\ncheckpoint = torch.load(checkpoint_path)\n\n# Load the state dict, stripping the 'module.' prefix\nstate_dict = checkpoint['model_state_dict']\nnew_state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\ntest_model.load_state_dict(new_state_dict)\n\noptimizer = torch.optim.RMSprop(model.parameters(), lr=0.001, alpha=0.9, momentum=0.9, weight_decay = 1e-5)\noptimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n\n# Extract loss and accuracy history\nloss_hist = checkpoint['loss_hist']\nacc_hist = checkpoint['accuracy_hist']\n\nprint(\"Loss History:\", loss_hist)\nprint(\"Accuracy History:\", acc_hist)","metadata":{"execution":{"iopub.status.busy":"2024-08-08T14:37:57.872917Z","iopub.execute_input":"2024-08-08T14:37:57.873236Z","iopub.status.idle":"2024-08-08T14:37:58.483413Z","shell.execute_reply.started":"2024-08-08T14:37:57.873208Z","shell.execute_reply":"2024-08-08T14:37:58.482426Z"},"trusted":true},"execution_count":130,"outputs":[{"name":"stdout","text":"Loss History: {'train': [2.9901792014187034, 2.1707179356705057, 1.8341338248415426, 1.8124313435771249, 1.6705312573096969, 1.1919589941813187, 0.9188829821280458, 0.9988550403240052, 1.101175282658501, 0.8069616239517927], 'val': [2.656839860697924, 2.0110171730235473, 1.7553924109976171, 1.7256363721217138, 1.8073886521792009, 1.1205631042436017, 0.8586647944935297, 0.99547142156605, 1.2087937669228699, 0.8227307216848357]}\nAccuracy History: {'train': [0.14315555555555556, 0.30724444444444443, 0.4155111111111111, 0.42906666666666665, 0.48893333333333333, 0.6365777777777778, 0.7205333333333334, 0.6966666666666667, 0.6673333333333333, 0.7575555555555555], 'val': [0.1816, 0.35213333333333335, 0.44466666666666665, 0.4636, 0.49346666666666666, 0.6648, 0.7392, 0.6985333333333333, 0.6417333333333334, 0.7570666666666667]}\n","output_type":"stream"}]},{"cell_type":"code","source":"def test_model(model, test_dataloader, device):\n        #validating now\n    print(\"validation\")\n    model.eval()\n    with torch.no_grad():\n        val_loss_epoch, val_acc_epoch = loss_acc_epoch(model,criterion, val_dataloader, False, check_id=False)\n\n    #         #every epoch, keep on selecting the best model sofar\n    #         if val_loss_epoch < best_loss:\n    #             best_loss = val_loss_epoch\n    #             best_model_wts = copy.deepcopy(model.state_dict())\n\n    #             torch.save(model.state_dict(), \"savemodel.pt\")\n    #             print(\"best model saved\")\n    print(f\"Val.loss: {val_loss_epoch}, Val.Acc: {val_acc_epoch:.5f} \")\n\n# Example usage\ntest_model(model, val_dataloader, device=device)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-08T14:38:46.608648Z","iopub.execute_input":"2024-08-08T14:38:46.609564Z","iopub.status.idle":"2024-08-08T14:39:56.952188Z","shell.execute_reply.started":"2024-08-08T14:38:46.609515Z","shell.execute_reply":"2024-08-08T14:39:56.950923Z"},"trusted":true},"execution_count":131,"outputs":[{"name":"stdout","text":"validation\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 118/118 [01:10<00:00,  1.68it/s]","output_type":"stream"},{"name":"stdout","text":"Val.loss: 0.8207268435823716, Val.Acc: 0.75773 \n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# def train(model, criteria, optimizer, n_epochs, train_dataloader, val_dataloader, device, val_iter=10):\n    \n#     train_losses=[]\n#     train_accs=[]\n#     val_losses=[]\n#     val_accs=[]\n    \n#     for epoch in range(1, n_epochs+1):\n        \n#         print(f\"Epoch {epoch} of {n_epochs}:\")\n        \n#         #------training------------\n        \n#         n_train_samples = len(train_dataloader.dataset)\n        \n#         #train mode activate\n#         model.train()\n#         epoch_train_loss = 0\n#         correct_preds=0\n#         epoch_train_acc = float(0)\n#         step=0\n        \n        \n#         #all the training that happens per epoch\n#         for images, targets in tqdm(train_dataloader):\n#             #iterates through the dataset in batches\n            \n#             images = images.to(device)\n#             targets = targets.to(device)\n#             optimizer.zero_grad()\n            \n#             #forward pass\n#             results = model(images)\n#             losses = criteria(results, targets.unsqueeze(1).float())\n            \n#             #backward pass\n#             losses.backward()\n#             optimizer.step()\n            \n#             epoch_train_loss += losses.item()\n#             epoch_train_acc += torch.sum(results.round() == targets.unsqueeze(1).float())\n            \n#             step +=1\n        \n#         #after going through the entire dataset calculate the train loss and accuracy\n#         epoch_train_loss /= step\n#         train_losses.append(epoch_train_loss)\n        \n#         epoch_train_acc /= float(n_train_samples)\n#         train_accs.append(epoch_train_acc)\n        \n#         print(f\"Epoch {epoch} Training Loss: {epoch_train_loss:.4f}\")\n#         print(f\"Epoch {epoch} Training Acc: {epoch_train_acc:.4f}\")\n        \n        \n#         #perform validation every few epochs\n#         if epoch % val_iter ==0:\n            \n#             #------validation------------\n#             n_val_samples = len(val_dataloader.dataset)\n            \n#             #evaluation mode activate\n#             model.eval()\n#             epoch_val_loss =0\n#             epoch_val_acc = float(0)\n#             val_step=0\n            \n#             with torch.no_grad():\n#                 for images, targets in tqdm(val_dataloader):\n#                     #iterates through the dataset in batches\n                    \n#                     images = images.to(device)\n#                     targets = targets.to(device)\n#                     optimizer.zero_grad()\n                    \n#                     #forward pass\n#                     results = model(images)\n#                     losses = criteria(results, targets.unsqueeze(1).float())\n                    \n#                     #no backward pass\n                    \n#                     epoch_val_loss += losses.item()\n                    \n#                     #rounding basically thresholds the output at 0.5\n#                     epoch_val_acc += torch.sum(results.round() == targets.unsqueeze(1).float())\n                    \n#                     val_step +=1\n        \n#                 #after going through the entire dataset calculate the validation loss and accuracy\n#                 epoch_val_loss /= val_step\n#                 val_losses.append(epoch_val_loss)\n#                 epoch_val_acc /= n_val_samples\n#                 val_accs.append(epoch_val_acc)\n        \n#         print(f\"Epoch {epoch} Validation Loss: {epoch_train_loss:.4f}\")\n#         print(f\"Epoch {epoch} Validation Acc: {epoch_train_acc:.4f}\")\n    \n#     return train_losses, val_losses, train_accs, val_accs","metadata":{"execution":{"iopub.status.busy":"2024-08-08T14:22:07.967961Z","iopub.status.idle":"2024-08-08T14:22:07.968358Z","shell.execute_reply.started":"2024-08-08T14:22:07.968171Z","shell.execute_reply":"2024-08-08T14:22:07.968187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}