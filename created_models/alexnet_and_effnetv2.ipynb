{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":269359,"sourceType":"datasetVersion","datasetId":111880},{"sourceId":9097401,"sourceType":"datasetVersion","datasetId":5490352}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import models, transforms\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision\nimport torchvision.transforms as transforms\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-08T08:53:59.080221Z","iopub.execute_input":"2024-08-08T08:53:59.081146Z","iopub.status.idle":"2024-08-08T08:54:04.404207Z","shell.execute_reply.started":"2024-08-08T08:53:59.081103Z","shell.execute_reply":"2024-08-08T08:54:04.403117Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport cv2\nfrom tqdm import tqdm\nfrom sklearn.utils import shuffle","metadata":{"execution":{"iopub.status.busy":"2024-08-08T08:54:05.615423Z","iopub.execute_input":"2024-08-08T08:54:05.616111Z","iopub.status.idle":"2024-08-08T08:54:06.763752Z","shell.execute_reply.started":"2024-08-08T08:54:05.616083Z","shell.execute_reply":"2024-08-08T08:54:06.762955Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_dir = '/kaggle/input/seen-dataset-12-class/Seen Datasets/train'\ntest_dir = '/kaggle/input/seen-dataset-12-class/Seen Datasets/val'\n# pred_dir = '../input/intel-image-classification/seg_pred/seg_pred'","metadata":{"execution":{"iopub.status.busy":"2024-08-08T08:54:08.724431Z","iopub.execute_input":"2024-08-08T08:54:08.725151Z","iopub.status.idle":"2024-08-08T08:54:08.729381Z","shell.execute_reply.started":"2024-08-08T08:54:08.725122Z","shell.execute_reply":"2024-08-08T08:54:08.728349Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# assign class labels\nclass_names =x\nclass_labels = {class_name:i for i, class_name in enumerate(class_names)}\nprint(class_labels)\n\nnumber_classes = len(class_names)\n\nIMAGE_SIZE = (150,150)","metadata":{"execution":{"iopub.status.busy":"2024-08-08T08:54:25.896205Z","iopub.execute_input":"2024-08-08T08:54:25.896911Z","iopub.status.idle":"2024-08-08T08:54:25.901950Z","shell.execute_reply.started":"2024-08-08T08:54:25.896879Z","shell.execute_reply":"2024-08-08T08:54:25.900980Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"{'Common-Rosefinch': 0, 'Asian-Green-Bee-Eater': 1, 'Common-Kingfisher': 2, 'Jungle-Babbler': 3, 'White-Wagtail': 4, 'Indian-Roller': 5, 'Brown-Headed-Barbet': 6, 'Common-Tailorbird': 7, 'Rufous-Treepie': 8, 'White-Breasted-Waterhen': 9, 'Forest-Wagtail': 10, 'Common-Myna': 11, 'Sarus-Crane': 12, 'House-Crow': 13, 'Hoopoe': 14, 'Coppersmith-Barbet': 15, 'Cattle-Egret': 16, 'Indian-Peacock': 17, 'White-Breasted-Kingfisher': 18, 'Gray-Wagtail': 19, 'Ruddy-Shelduck': 20, 'Red-Wattled-Lapwing': 21, 'Indian-Pitta': 22, 'Indian-Grey-Hornbill': 23, 'Northern-Lapwing': 24}\n","output_type":"stream"}]},{"cell_type":"code","source":"x\n","metadata":{"execution":{"iopub.status.busy":"2024-08-08T08:54:23.710960Z","iopub.execute_input":"2024-08-08T08:54:23.711290Z","iopub.status.idle":"2024-08-08T08:54:23.718588Z","shell.execute_reply.started":"2024-08-08T08:54:23.711266Z","shell.execute_reply":"2024-08-08T08:54:23.717421Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"['Common-Rosefinch',\n 'Asian-Green-Bee-Eater',\n 'Common-Kingfisher',\n 'Jungle-Babbler',\n 'White-Wagtail',\n 'Indian-Roller',\n 'Brown-Headed-Barbet',\n 'Common-Tailorbird',\n 'Rufous-Treepie',\n 'White-Breasted-Waterhen',\n 'Forest-Wagtail',\n 'Common-Myna',\n 'Sarus-Crane',\n 'House-Crow',\n 'Hoopoe',\n 'Coppersmith-Barbet',\n 'Cattle-Egret',\n 'Indian-Peacock',\n 'White-Breasted-Kingfisher',\n 'Gray-Wagtail',\n 'Ruddy-Shelduck',\n 'Red-Wattled-Lapwing',\n 'Indian-Pitta',\n 'Indian-Grey-Hornbill',\n 'Northern-Lapwing']"},"metadata":{}}]},{"cell_type":"code","source":"x=[]\nfor folder in os.listdir(train_dir):\n    x.append(folder)\n#     print(x)","metadata":{"execution":{"iopub.status.busy":"2024-08-08T08:54:20.346479Z","iopub.execute_input":"2024-08-08T08:54:20.346882Z","iopub.status.idle":"2024-08-08T08:54:20.359785Z","shell.execute_reply.started":"2024-08-08T08:54:20.346853Z","shell.execute_reply":"2024-08-08T08:54:20.358815Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# usecase of os.listdir and os.path.join functions\nfor folder in os.listdir(train_dir):\n    files_path = []\n    for file in os.listdir(os.path.join(train_dir,folder)):\n        files_path.append(file)\n    print(len(files_path))","metadata":{"execution":{"iopub.status.busy":"2024-08-08T08:54:30.376208Z","iopub.execute_input":"2024-08-08T08:54:30.377102Z","iopub.status.idle":"2024-08-08T08:54:35.011225Z","shell.execute_reply.started":"2024-08-08T08:54:30.377068Z","shell.execute_reply":"2024-08-08T08:54:35.010260Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"900\n900\n900\n900\n900\n900\n900\n900\n900\n900\n900\n900\n900\n900\n900\n900\n900\n900\n900\n900\n900\n900\n900\n900\n900\n","output_type":"stream"}]},{"cell_type":"code","source":"# define load_dataset function to load dataset with labels\ndef load_dataset():\n    # create list of datasets\n    datasets = [train_dir, test_dir]\n    output = []\n    \n    for dataset in datasets:\n        images1 = []\n        labels1 = []\n        print(f\"loading {dataset}\")\n        \n        for folder in os.listdir(dataset):\n            label = class_labels[folder]\n            \n            for file in tqdm(os.listdir(os.path.join(dataset,folder))):\n                image_path = os.path.join(os.path.join(dataset, folder), file)\n                \n                image_file = cv2.imread(image_path)\n                image_file = cv2.cvtColor(image_file, cv2.COLOR_BGR2RGB)\n                \n                image_file = cv2.resize(image_file, IMAGE_SIZE)\n                \n                images1.append(image_file)\n                labels1.append(label)\n                \n        images1 = np.array(images1, dtype = 'float32')\n        labels1 = np.array(labels1, dtype = 'int32')\n        \n        output.append((images1, labels1))\n        print(\"Images file have been loaded\")\n                \n    return output ","metadata":{"execution":{"iopub.status.busy":"2024-08-08T08:54:39.746021Z","iopub.execute_input":"2024-08-08T08:54:39.746416Z","iopub.status.idle":"2024-08-08T08:54:39.754857Z","shell.execute_reply.started":"2024-08-08T08:54:39.746386Z","shell.execute_reply":"2024-08-08T08:54:39.753963Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom tqdm import tqdm\n\ndef load_dataset():\n    # create list of datasets\n    datasets = [train_dir, test_dir]\n    output = []\n    \n    for dataset in datasets:\n        images1 = []\n        labels1 = []\n        print(f\"loading {dataset}\")\n        \n        for folder in os.listdir(dataset):\n            label = class_labels.get(folder)\n            if label is None:\n                print(f\"Warning: No label found for folder {folder}. Skipping.\")\n                continue\n            \n            folder_path = os.path.join(dataset, folder)\n            for file in tqdm(os.listdir(folder_path)):\n                image_path = os.path.join(folder_path, file)\n                \n                image_file = cv2.imread(image_path)\n                if image_file is None:\n                    print(f\"Warning: Could not read image {image_path}. Skipping.\")\n                    continue\n                \n                image_file = cv2.cvtColor(image_file, cv2.COLOR_BGR2RGB)\n                image_file = cv2.resize(image_file, IMAGE_SIZE)\n                \n                images1.append(image_file)\n                labels1.append(label)\n                \n        images1 = np.array(images1, dtype='float32')\n        labels1 = np.array(labels1, dtype='int32')\n        \n        output.append((images1, labels1))\n        print(\"Images have been loaded.\")\n                \n    return output\n","metadata":{"execution":{"iopub.status.busy":"2024-08-08T08:54:44.415233Z","iopub.execute_input":"2024-08-08T08:54:44.416017Z","iopub.status.idle":"2024-08-08T08:54:44.426205Z","shell.execute_reply.started":"2024-08-08T08:54:44.415985Z","shell.execute_reply":"2024-08-08T08:54:44.425168Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load the data using above functions\n((train_images, train_labels), (test_images, test_labels)) = load_dataset()","metadata":{"execution":{"iopub.status.busy":"2024-08-08T08:54:48.564191Z","iopub.execute_input":"2024-08-08T08:54:48.565098Z","iopub.status.idle":"2024-08-08T09:00:57.348896Z","shell.execute_reply.started":"2024-08-08T08:54:48.565062Z","shell.execute_reply":"2024-08-08T09:00:57.347922Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"loading /kaggle/input/seen-dataset-12-class/Seen Datasets/train\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 900/900 [00:10<00:00, 89.67it/s] \n100%|██████████| 900/900 [00:09<00:00, 98.28it/s] \n100%|██████████| 900/900 [00:09<00:00, 96.15it/s] \n100%|██████████| 900/900 [00:11<00:00, 77.87it/s]\n100%|██████████| 900/900 [00:11<00:00, 78.31it/s]\n100%|██████████| 900/900 [00:09<00:00, 93.12it/s] \n100%|██████████| 900/900 [00:10<00:00, 82.13it/s]\n100%|██████████| 900/900 [00:09<00:00, 93.06it/s] \n100%|██████████| 900/900 [00:12<00:00, 73.11it/s]\n100%|██████████| 900/900 [00:13<00:00, 68.27it/s]\n100%|██████████| 900/900 [00:09<00:00, 91.35it/s] \n100%|██████████| 900/900 [00:09<00:00, 92.68it/s]\n 25%|██▌       | 226/900 [00:04<00:12, 56.13it/s]","output_type":"stream"},{"name":"stdout","text":"Warning: Could not read image /kaggle/input/seen-dataset-12-class/Seen Datasets/train/Sarus-Crane/Sarus-Crane_14.jpg. Skipping.\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 900/900 [00:16<00:00, 53.73it/s]\n100%|██████████| 900/900 [00:09<00:00, 93.77it/s] \n100%|██████████| 900/900 [00:09<00:00, 90.70it/s]\n100%|██████████| 900/900 [00:09<00:00, 90.33it/s] \n100%|██████████| 900/900 [00:10<00:00, 88.75it/s]\n100%|██████████| 900/900 [00:11<00:00, 77.80it/s]\n100%|██████████| 900/900 [00:11<00:00, 76.31it/s]\n100%|██████████| 900/900 [00:09<00:00, 95.68it/s] \n100%|██████████| 900/900 [00:13<00:00, 69.06it/s]\n100%|██████████| 900/900 [00:13<00:00, 67.60it/s]\n100%|██████████| 900/900 [00:10<00:00, 88.34it/s]\n100%|██████████| 900/900 [00:10<00:00, 88.32it/s]\n100%|██████████| 900/900 [00:11<00:00, 76.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Images have been loaded.\nloading /kaggle/input/seen-dataset-12-class/Seen Datasets/val\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 300/300 [00:03<00:00, 94.41it/s]\n100%|██████████| 300/300 [00:02<00:00, 104.67it/s]\n100%|██████████| 300/300 [00:03<00:00, 99.81it/s] \n100%|██████████| 300/300 [00:04<00:00, 71.80it/s]\n100%|██████████| 300/300 [00:03<00:00, 77.54it/s]\n100%|██████████| 300/300 [00:03<00:00, 93.71it/s] \n100%|██████████| 300/300 [00:03<00:00, 90.51it/s]\n100%|██████████| 300/300 [00:03<00:00, 94.29it/s]\n100%|██████████| 300/300 [00:04<00:00, 72.76it/s]\n100%|██████████| 300/300 [00:04<00:00, 71.10it/s]\n100%|██████████| 300/300 [00:03<00:00, 90.84it/s]\n100%|██████████| 300/300 [00:03<00:00, 93.62it/s]\n100%|██████████| 300/300 [00:05<00:00, 53.40it/s]\n100%|██████████| 300/300 [00:03<00:00, 96.15it/s]\n100%|██████████| 300/300 [00:03<00:00, 96.20it/s]\n100%|██████████| 300/300 [00:03<00:00, 96.45it/s] \n100%|██████████| 300/300 [00:03<00:00, 96.44it/s]\n100%|██████████| 300/300 [00:03<00:00, 79.29it/s]\n100%|██████████| 300/300 [00:03<00:00, 81.22it/s]\n100%|██████████| 300/300 [00:03<00:00, 95.70it/s]\n100%|██████████| 300/300 [00:04<00:00, 68.55it/s]\n100%|██████████| 300/300 [00:04<00:00, 68.29it/s]\n100%|██████████| 300/300 [00:03<00:00, 85.52it/s]\n100%|██████████| 300/300 [00:03<00:00, 87.78it/s]\n100%|██████████| 300/300 [00:04<00:00, 73.25it/s]\n","output_type":"stream"},{"name":"stdout","text":"Images have been loaded.\n","output_type":"stream"}]},{"cell_type":"code","source":"train_images.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-08T09:01:09.007364Z","iopub.execute_input":"2024-08-08T09:01:09.007714Z","iopub.status.idle":"2024-08-08T09:01:09.014080Z","shell.execute_reply.started":"2024-08-08T09:01:09.007687Z","shell.execute_reply":"2024-08-08T09:01:09.013133Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(22499, 150, 150, 3)"},"metadata":{}}]},{"cell_type":"code","source":"print(\"train dataset size\")\nlen(train_images), len(train_labels)","metadata":{"execution":{"iopub.status.busy":"2024-08-08T09:01:14.820577Z","iopub.execute_input":"2024-08-08T09:01:14.820973Z","iopub.status.idle":"2024-08-08T09:01:14.828266Z","shell.execute_reply.started":"2024-08-08T09:01:14.820937Z","shell.execute_reply":"2024-08-08T09:01:14.827273Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"train dataset size\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"(22499, 22499)"},"metadata":{}}]},{"cell_type":"code","source":"print(\"test dataset size\")\nlen(test_images), len(test_labels)","metadata":{"execution":{"iopub.status.busy":"2024-08-08T09:01:13.118056Z","iopub.execute_input":"2024-08-08T09:01:13.118689Z","iopub.status.idle":"2024-08-08T09:01:13.125054Z","shell.execute_reply.started":"2024-08-08T09:01:13.118658Z","shell.execute_reply":"2024-08-08T09:01:13.124179Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"test dataset size\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(7500, 7500)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Pre-processing","metadata":{}},{"cell_type":"code","source":"# shape of image dataset is in 4D \ntrain_images.shape, test_images.shape","metadata":{"execution":{"iopub.status.busy":"2024-08-08T09:01:32.325559Z","iopub.execute_input":"2024-08-08T09:01:32.326601Z","iopub.status.idle":"2024-08-08T09:01:32.332722Z","shell.execute_reply.started":"2024-08-08T09:01:32.326562Z","shell.execute_reply":"2024-08-08T09:01:32.331807Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"((17000, 150, 150, 3), (5000, 150, 150, 3))"},"metadata":{}}]},{"cell_type":"code","source":"# shuffle train and test datasets\n(train_images, train_labels) = shuffle(train_images, train_labels, random_state=45)","metadata":{"execution":{"iopub.status.busy":"2024-08-08T09:01:19.983018Z","iopub.execute_input":"2024-08-08T09:01:19.983850Z","iopub.status.idle":"2024-08-08T09:01:21.721598Z","shell.execute_reply.started":"2024-08-08T09:01:19.983818Z","shell.execute_reply":"2024-08-08T09:01:21.720601Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"(test_images, test_labels) = shuffle(test_images, test_labels, random_state=45)","metadata":{"execution":{"iopub.status.busy":"2024-08-08T09:01:23.084854Z","iopub.execute_input":"2024-08-08T09:01:23.085479Z","iopub.status.idle":"2024-08-08T09:01:23.658936Z","shell.execute_reply.started":"2024-08-08T09:01:23.085449Z","shell.execute_reply":"2024-08-08T09:01:23.658153Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# keeping 6000 data instances for training and testing our model\ntrain_images = train_images[:17000]\ntrain_labels = train_labels[:17000]","metadata":{"execution":{"iopub.status.busy":"2024-08-08T09:01:25.758016Z","iopub.execute_input":"2024-08-08T09:01:25.758699Z","iopub.status.idle":"2024-08-08T09:01:25.763263Z","shell.execute_reply.started":"2024-08-08T09:01:25.758669Z","shell.execute_reply":"2024-08-08T09:01:25.762302Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"test_images = test_images[:5000]\ntest_labels = test_labels[:5000]","metadata":{"execution":{"iopub.status.busy":"2024-08-08T09:01:29.846637Z","iopub.execute_input":"2024-08-08T09:01:29.847070Z","iopub.status.idle":"2024-08-08T09:01:29.854792Z","shell.execute_reply.started":"2024-08-08T09:01:29.847037Z","shell.execute_reply":"2024-08-08T09:01:29.853862Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# normalize the images dataset\ntrn_images_norm = train_images/255.0\ntst_images_norm = test_images/255.0","metadata":{"execution":{"iopub.status.busy":"2024-08-08T09:01:35.428662Z","iopub.execute_input":"2024-08-08T09:01:35.429271Z","iopub.status.idle":"2024-08-08T09:01:37.134836Z","shell.execute_reply.started":"2024-08-08T09:01:35.429238Z","shell.execute_reply":"2024-08-08T09:01:37.134009Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"model = models.efficientnet_b3(pretrained=False)\n\n# Modify the classifier to have 25 output classes instead of 1000\nmodel.classifier[1] = nn.Linear(model.classifier[1].in_features, 25)","metadata":{"execution":{"iopub.status.busy":"2024-08-08T09:16:16.491175Z","iopub.execute_input":"2024-08-08T09:16:16.491897Z","iopub.status.idle":"2024-08-08T09:16:16.765168Z","shell.execute_reply.started":"2024-08-08T09:16:16.491867Z","shell.execute_reply":"2024-08-08T09:16:16.764405Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"}]},{"cell_type":"code","source":"def initialize_weights(m):\n    if isinstance(m, nn.Conv2d):\n        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n        if m.bias is not None:\n            nn.init.constant_(m.bias, 0)\n    elif isinstance(m, nn.BatchNorm2d):\n        nn.init.constant_(m.weight, 1)\n        nn.init.constant_(m.bias, 0)\n    elif isinstance(m, nn.Linear):\n        nn.init.normal_(m.weight, 0, 0.01)\n        nn.init.constant_(m.bias, 0)\n\n# Apply the weight initialization\nmodel.apply(initialize_weights)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-08T09:16:19.110979Z","iopub.execute_input":"2024-08-08T09:16:19.111660Z","iopub.status.idle":"2024-08-08T09:16:19.237693Z","shell.execute_reply.started":"2024-08-08T09:16:19.111627Z","shell.execute_reply":"2024-08-08T09:16:19.236756Z"},"trusted":true},"execution_count":71,"outputs":[{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"EfficientNet(\n  (features): Sequential(\n    (0): Conv2dNormActivation(\n      (0): Conv2d(3, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): SiLU(inplace=True)\n    )\n    (1): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (2): Conv2dNormActivation(\n            (0): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (2): Conv2dNormActivation(\n            (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.007692307692307693, mode=row)\n      )\n    )\n    (2): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.015384615384615385, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.02307692307692308, mode=row)\n      )\n      (2): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.03076923076923077, mode=row)\n      )\n    )\n    (3): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.038461538461538464, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.04615384615384616, mode=row)\n      )\n      (2): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.05384615384615385, mode=row)\n      )\n    )\n    (4): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)\n            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.06153846153846154, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.06923076923076923, mode=row)\n      )\n      (2): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.07692307692307693, mode=row)\n      )\n      (3): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.08461538461538462, mode=row)\n      )\n      (4): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.09230769230769233, mode=row)\n      )\n    )\n    (5): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1076923076923077, mode=row)\n      )\n      (2): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.11538461538461539, mode=row)\n      )\n      (3): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.12307692307692308, mode=row)\n      )\n      (4): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.13076923076923078, mode=row)\n      )\n    )\n    (6): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=816, bias=False)\n            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.13846153846153847, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.14615384615384616, mode=row)\n      )\n      (2): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.15384615384615385, mode=row)\n      )\n      (3): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.16153846153846155, mode=row)\n      )\n      (4): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.16923076923076924, mode=row)\n      )\n      (5): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.17692307692307693, mode=row)\n      )\n    )\n    (7): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1392, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1392, bias=False)\n            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.18461538461538465, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n            (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.19230769230769232, mode=row)\n      )\n    )\n    (8): Conv2dNormActivation(\n      (0): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): SiLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=1)\n  (classifier): Sequential(\n    (0): Dropout(p=0.3, inplace=True)\n    (1): Linear(in_features=1536, out_features=25, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Input: 224x224 RGB image\n# |\n# |--> [Conv7x7, 64, stride 2] -> [MaxPool, 3x3, stride 2]\n# |\n# |--> Stage 1: [2 x {3x3, 64} residual blocks]\n# |\n# |--> Stage 2: [2 x {3x3, 128} residual blocks, first with stride 2]\n# |\n# |--> Stage 3: [2 x {3x3, 256} residual blocks, first with stride 2]\n# |\n# |--> Stage 4: [2 x {3x3, 512} residual blocks, first with stride 2]\n# |\n# |--> Global Average Pooling\n# |\n# |--> Fully Connected (1000)\n# |\n# Output: 1000 class scores\n","metadata":{"execution":{"iopub.status.busy":"2024-08-05T08:44:34.607258Z","iopub.execute_input":"2024-08-05T08:44:34.607711Z","iopub.status.idle":"2024-08-05T08:44:34.615135Z","shell.execute_reply.started":"2024-08-05T08:44:34.607668Z","shell.execute_reply":"2024-08-05T08:44:34.613818Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-08T09:16:22.698938Z","iopub.execute_input":"2024-08-08T09:16:22.699540Z","iopub.status.idle":"2024-08-08T09:16:22.746542Z","shell.execute_reply.started":"2024-08-08T09:16:22.699508Z","shell.execute_reply":"2024-08-08T09:16:22.745536Z"},"trusted":true},"execution_count":72,"outputs":[{"execution_count":72,"output_type":"execute_result","data":{"text/plain":"EfficientNet(\n  (features): Sequential(\n    (0): Conv2dNormActivation(\n      (0): Conv2d(3, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): SiLU(inplace=True)\n    )\n    (1): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (2): Conv2dNormActivation(\n            (0): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (2): Conv2dNormActivation(\n            (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.007692307692307693, mode=row)\n      )\n    )\n    (2): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.015384615384615385, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.02307692307692308, mode=row)\n      )\n      (2): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.03076923076923077, mode=row)\n      )\n    )\n    (3): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.038461538461538464, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.04615384615384616, mode=row)\n      )\n      (2): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.05384615384615385, mode=row)\n      )\n    )\n    (4): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)\n            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.06153846153846154, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.06923076923076923, mode=row)\n      )\n      (2): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.07692307692307693, mode=row)\n      )\n      (3): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.08461538461538462, mode=row)\n      )\n      (4): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.09230769230769233, mode=row)\n      )\n    )\n    (5): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1076923076923077, mode=row)\n      )\n      (2): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.11538461538461539, mode=row)\n      )\n      (3): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.12307692307692308, mode=row)\n      )\n      (4): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.13076923076923078, mode=row)\n      )\n    )\n    (6): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(816, 816, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=816, bias=False)\n            (1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.13846153846153847, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.14615384615384616, mode=row)\n      )\n      (2): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.15384615384615385, mode=row)\n      )\n      (3): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.16153846153846155, mode=row)\n      )\n      (4): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.16923076923076924, mode=row)\n      )\n      (5): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.17692307692307693, mode=row)\n      )\n    )\n    (7): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1392, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1392, bias=False)\n            (1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.18461538461538465, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n            (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.19230769230769232, mode=row)\n      )\n    )\n    (8): Conv2dNormActivation(\n      (0): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): SiLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=1)\n  (classifier): Sequential(\n    (0): Dropout(p=0.3, inplace=True)\n    (1): Linear(in_features=1536, out_features=25, bias=True)\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n\n# Training loop\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    with tqdm(total=len(trainloader), desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch') as pbar:\n        for inputs, labels in trainloader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            labels = labels.long()  # Convert labels to LongTensor\n\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n            pbar.set_postfix(loss=running_loss/(pbar.n+1))\n            pbar.update(1)\n    \n    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(trainloader)}\")\n\nprint(\"Training complete.\")","metadata":{"execution":{"iopub.status.busy":"2024-08-08T09:16:25.190888Z","iopub.execute_input":"2024-08-08T09:16:25.191767Z","iopub.status.idle":"2024-08-08T09:24:29.067708Z","shell.execute_reply.started":"2024-08-08T09:16:25.191732Z","shell.execute_reply":"2024-08-08T09:24:29.066331Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stderr","text":"Epoch 1/10: 100%|██████████| 266/266 [01:25<00:00,  3.12batch/s, loss=2.91]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10, Loss: 2.91277663779438\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/10: 100%|██████████| 266/266 [01:27<00:00,  3.03batch/s, loss=2.57]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/10, Loss: 2.5701177783478473\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/10: 100%|██████████| 266/266 [01:29<00:00,  2.97batch/s, loss=2.28]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/10, Loss: 2.2803913722360942\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/10: 100%|██████████| 266/266 [01:30<00:00,  2.95batch/s, loss=2.01]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/10, Loss: 2.0131376175055826\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/10: 100%|██████████| 266/266 [01:30<00:00,  2.95batch/s, loss=1.78]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/10, Loss: 1.7832959666287989\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/10:  44%|████▍     | 118/266 [00:40<00:50,  2.91batch/s, loss=1.62]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[73], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 21\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39mrunning_loss\u001b[38;5;241m/\u001b[39m(pbar\u001b[38;5;241m.\u001b[39mn\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     23\u001b[0m pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"model=0","metadata":{"execution":{"iopub.status.busy":"2024-08-08T10:07:27.196198Z","iopub.execute_input":"2024-08-08T10:07:27.196639Z","iopub.status.idle":"2024-08-08T10:07:27.232468Z","shell.execute_reply.started":"2024-08-08T10:07:27.196610Z","shell.execute_reply":"2024-08-08T10:07:27.231622Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"device=torch.device('cuda')","metadata":{"execution":{"iopub.status.busy":"2024-08-08T08:44:47.198346Z","iopub.execute_input":"2024-08-08T08:44:47.199081Z","iopub.status.idle":"2024-08-08T08:44:47.203435Z","shell.execute_reply.started":"2024-08-08T08:44:47.199043Z","shell.execute_reply":"2024-08-08T08:44:47.202530Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\n\n# ConvBlock\nclass ConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride, groups=1, act=True, bias=False):\n        super().__init__()\n        \"\"\" If k = 1 -> p = 0, k = 3 -> p = 1, k = 5, p = 2. \"\"\"\n        padding = kernel_size // 2\n        self.c = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias, groups=groups)\n        self.bn = nn.BatchNorm2d(out_channels)\n        self.silu = nn.SiLU() if act else nn.Identity()\n\n    def forward(self, x):\n        x = self.silu(self.bn(self.c(x)))\n        return x\n\n# Squeeze-and-Excitation Block\nclass SeBlock(nn.Module):\n    def __init__(self, in_channels, r):\n        super().__init__()\n        C = in_channels\n        self.globpool = nn.AdaptiveAvgPool2d((1,1))\n        self.fc1 = nn.Linear(C, C//r, bias=False)\n        self.fc2 = nn.Linear(C//r, C, bias=False)\n        self.silu = nn.SiLU()\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        \"\"\" x shape: [N, C, H, W]. \"\"\" \n        f = self.globpool(x)\n        f = torch.flatten(f,1)\n        f = self.silu(self.fc1(f))\n        f = self.sigmoid(self.fc2(f))\n        f = f[:,:,None,None]\n        \"\"\" f shape: [N, C, 1, 1] \"\"\" \n\n        scale = x * f\n        return scale\n\n# MBConv\nclass MBConv(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, stride, exp, r):\n        super().__init__()\n        exp_channels = in_channels * exp\n        self.add = in_channels == out_channels and stride == 1\n        self.c1 = ConvBlock(in_channels, exp_channels, 1, 1) if exp > 1 else nn.Identity()\n        self.c2 = ConvBlock(exp_channels, exp_channels, kernel_size, stride, exp_channels)\n        self.se = SeBlock(exp_channels, r)\n        self.c3 = ConvBlock(exp_channels, out_channels, 1, 1, act=False)\n\n        \" Stochastic Depth module with default survival probability 0.5. \"\n        self.sd = StochasticDepth()\n\n    def forward(self, x):\n        f = self.c1(x)\n        f = self.c2(f)\n        f = self.se(f)\n        f = self.c3(f)\n\n        if self.add:\n            f = x + f\n\n        f = self.sd(f)\n\n        return f\n\n# Classfier\nclass Classifier(nn.Module):\n    \"\"\" Last stage with Average Pooling and Fully-Connected layer. \"\"\" \n    def __init__(self, in_channels, classes, p):\n        super().__init__()\n        self.pool = nn.AdaptiveAvgPool2d((1,1))\n        self.fc = nn.Linear(in_channels, classes)\n        self.dropout = nn.Dropout(p)\n\n    def forward(self, x):\n        x = self.dropout(self.pool(x))\n        x = torch.flatten(x, 1)\n        return self.fc(x)\n\n# EfficientNet\nclass EfficientNet(nn.Module):\n    def __init__(\n        self, \n        model_config : str,\n        in_channels : int = 3, \n        classes : int = 25,\n        show : str = False\n        ):\n        super().__init__()\n        self.show = show # if True print the output dim between layers \n        config = Config()\n        stages = config.stages\n        phis = config.phis[model_config]\n\n        \"\"\" Parameters. \"\"\"\n        phi, res, p = phis\n        self._calculate_coef(phi)\n\n        \"\"\" Network. \"\"\"\n        self.net = nn.ModuleList([])\n        self.channels = []\n\n        \"\"\" First stage Conv3x3. \"\"\"\n        f, c, l, k, s, exp = stages[0]\n        self._add_layer(3, f, c, l, k, s)\n\n        \"\"\" 2-8 stages with MBConvs. \"\"\"\n        for i in range(1, len(stages)-1):\n            if i == 1:\n                r = 4\n            else:\n                r = 24\n\n            f, c, l, k, s, exp = stages[i]\n            self._add_layer(self.channels[-1], f, c, l, k, s, exp, r)\n\n        \"\"\" Last stage Conv1x1 + Classifier. \"\"\"\n        f, c, l, k, s, exp = stages[-1]\n        self._add_layer(self.channels[-1], f, c, l, k, s)\n        self.net.append(Classifier(self.channels[-1], classes, p))\n\n    def forward(self, x):\n        ''' Fancy way to print shapes of certain stages. '''\n        i = 1\n        for F in self.net:\n            in_feat, h, w = x.shape[1:]\n            \n            \n            x = F(x)\n            if in_feat != x.shape[1] and i < 10:\n                if self.show : print(\"Stage {} -> \".format(i), [x.shape[1], h, w])\n                i += 1\n        return x\n\n    def _add_layer(self, in_channels, f, c, l, k, s, *args):\n        c, l = self._update_feat(c, l)\n        if l == 1:\n            self.net.append(f(in_channels, c, k, s, *args))\n        else:\n            \"\"\" First layer with stride 1. \"\"\"\n            self.net.append(f(in_channels, c, k, 1, *args))\n            \n            \"\"\" Another layers with stride 1. \"\"\"\n            for _ in range(l-2):\n                self.net.append(f(c, c, k, 1, *args))                \n        \n            \"\"\" Final layer with stride s(1 or 2). \"\"\"\n            self.net.append(f(c, c, k, s, *args))\n\n        self.channels.append(c)\n                \n    def _calculate_coef(self, phi, alpha=1.2, beta=1.1):\n        self.d = alpha**phi\n        self.w = beta**phi\n\n    def _update_feat(self, c, l):\n        return int(c * self.w), int(l * self.d)\n\nclass Config:\n    stages = [\n            # [Operator(f), Channels(c), Layers(l), Kernel(k), Stride(s), Expansion(exp)]\n            [ConvBlock, 32, 1, 3, 2, 1], \n            [MBConv, 16, 1, 3, 1, 1],\n            [MBConv, 24, 2, 3, 2, 6],\n            [MBConv, 40, 2, 5, 2, 6],\n            [MBConv, 80, 3, 3, 2, 6],\n            [MBConv, 112, 3, 5, 1, 6],\n            [MBConv, 192, 4, 5, 2, 6],\n            [MBConv, 320, 1, 3, 1, 6],\n            [ConvBlock, 1280, 1, 1, 1, 0]\n    ]\n\n    phis = {\n            # BX : (phi, resolution, dropout) \n            \"B0\" : (0, 224, 0.2), \n            \"B1\" : (0.5, 240, 0.2),\n            \"B2\" : (1, 260, 0.3),\n            \"B3\" : (2, 300, 0.3),\n            \"B4\" : (3, 380, 0.4),\n            \"B5\" : (4, 456, 0.4),\n            \"B6\" : (5, 528, 0.5),\n            \"B7\" : (6, 600, 0.5)\n    }\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-08T09:24:32.439338Z","iopub.execute_input":"2024-08-08T09:24:32.439850Z","iopub.status.idle":"2024-08-08T09:24:32.475942Z","shell.execute_reply.started":"2024-08-08T09:24:32.439805Z","shell.execute_reply":"2024-08-08T09:24:32.475096Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import Tensor\nimport torch.nn as nn \n\nclass StochasticDepth(nn.Module):\n    \" Stochastic Depth / Drop Path module which takes survival probability(p) and returns input with *dropped* examples in the batch. \"\n    \n    def __init__(\n        self,\n        p : float = 0.5\n        ):\n        super().__init__()\n        self.p = p\n        \n    def forward(self, x: Tensor) -> Tensor:\n        mask_shape = (x.shape[0],) + (1,)*(x.ndim - 1)\n        # mask shape: [batch, 1, 1, 1]\n        mask = torch.empty(mask_shape, device=x.device).bernoulli_(self.p) / self.p\n        \n        if self.training : x = mask * x\n        return x \n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-08T09:24:41.932421Z","iopub.execute_input":"2024-08-08T09:24:41.933039Z","iopub.status.idle":"2024-08-08T09:24:41.940050Z","shell.execute_reply.started":"2024-08-08T09:24:41.933009Z","shell.execute_reply":"2024-08-08T09:24:41.939032Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"# model=0","metadata":{"execution":{"iopub.status.busy":"2024-08-08T09:25:04.083691Z","iopub.execute_input":"2024-08-08T09:25:04.084781Z","iopub.status.idle":"2024-08-08T09:25:04.089410Z","shell.execute_reply.started":"2024-08-08T09:25:04.084739Z","shell.execute_reply":"2024-08-08T09:25:04.088297Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"\nmodel_config = \"B3\" \nmodel = EfficientNet(model_config)\n\ndevice = torch.device('cuda')\nmodel.to(device)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-08T09:25:13.467194Z","iopub.execute_input":"2024-08-08T09:25:13.467826Z","iopub.status.idle":"2024-08-08T09:25:13.590823Z","shell.execute_reply.started":"2024-08-08T09:25:13.467792Z","shell.execute_reply":"2024-08-08T09:25:13.589783Z"},"trusted":true},"execution_count":79,"outputs":[{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"EfficientNet(\n  (net): ModuleList(\n    (0): ConvBlock(\n      (c): Conv2d(3, 38, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (silu): SiLU()\n    )\n    (1): MBConv(\n      (c1): Identity()\n      (c2): ConvBlock(\n        (c): Conv2d(38, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=38, bias=False)\n        (bn): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (se): SeBlock(\n        (globpool): AdaptiveAvgPool2d(output_size=(1, 1))\n        (fc1): Linear(in_features=38, out_features=9, bias=False)\n        (fc2): Linear(in_features=9, out_features=38, bias=False)\n        (silu): SiLU()\n        (sigmoid): Sigmoid()\n      )\n      (c3): ConvBlock(\n        (c): Conv2d(38, 19, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): Identity()\n      )\n      (sd): StochasticDepth()\n    )\n    (2): MBConv(\n      (c1): ConvBlock(\n        (c): Conv2d(19, 114, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(114, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (c2): ConvBlock(\n        (c): Conv2d(114, 114, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=114, bias=False)\n        (bn): BatchNorm2d(114, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (se): SeBlock(\n        (globpool): AdaptiveAvgPool2d(output_size=(1, 1))\n        (fc1): Linear(in_features=114, out_features=4, bias=False)\n        (fc2): Linear(in_features=4, out_features=114, bias=False)\n        (silu): SiLU()\n        (sigmoid): Sigmoid()\n      )\n      (c3): ConvBlock(\n        (c): Conv2d(114, 29, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): Identity()\n      )\n      (sd): StochasticDepth()\n    )\n    (3): MBConv(\n      (c1): ConvBlock(\n        (c): Conv2d(29, 174, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(174, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (c2): ConvBlock(\n        (c): Conv2d(174, 174, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=174, bias=False)\n        (bn): BatchNorm2d(174, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (se): SeBlock(\n        (globpool): AdaptiveAvgPool2d(output_size=(1, 1))\n        (fc1): Linear(in_features=174, out_features=7, bias=False)\n        (fc2): Linear(in_features=7, out_features=174, bias=False)\n        (silu): SiLU()\n        (sigmoid): Sigmoid()\n      )\n      (c3): ConvBlock(\n        (c): Conv2d(174, 29, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): Identity()\n      )\n      (sd): StochasticDepth()\n    )\n    (4): MBConv(\n      (c1): ConvBlock(\n        (c): Conv2d(29, 174, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(174, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (c2): ConvBlock(\n        (c): Conv2d(174, 174, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=174, bias=False)\n        (bn): BatchNorm2d(174, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (se): SeBlock(\n        (globpool): AdaptiveAvgPool2d(output_size=(1, 1))\n        (fc1): Linear(in_features=174, out_features=7, bias=False)\n        (fc2): Linear(in_features=7, out_features=174, bias=False)\n        (silu): SiLU()\n        (sigmoid): Sigmoid()\n      )\n      (c3): ConvBlock(\n        (c): Conv2d(174, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): Identity()\n      )\n      (sd): StochasticDepth()\n    )\n    (5): MBConv(\n      (c1): ConvBlock(\n        (c): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (c2): ConvBlock(\n        (c): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n        (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (se): SeBlock(\n        (globpool): AdaptiveAvgPool2d(output_size=(1, 1))\n        (fc1): Linear(in_features=288, out_features=12, bias=False)\n        (fc2): Linear(in_features=12, out_features=288, bias=False)\n        (silu): SiLU()\n        (sigmoid): Sigmoid()\n      )\n      (c3): ConvBlock(\n        (c): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): Identity()\n      )\n      (sd): StochasticDepth()\n    )\n    (6): MBConv(\n      (c1): ConvBlock(\n        (c): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (c2): ConvBlock(\n        (c): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n        (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (se): SeBlock(\n        (globpool): AdaptiveAvgPool2d(output_size=(1, 1))\n        (fc1): Linear(in_features=288, out_features=12, bias=False)\n        (fc2): Linear(in_features=12, out_features=288, bias=False)\n        (silu): SiLU()\n        (sigmoid): Sigmoid()\n      )\n      (c3): ConvBlock(\n        (c): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): Identity()\n      )\n      (sd): StochasticDepth()\n    )\n    (7-8): 2 x MBConv(\n      (c1): ConvBlock(\n        (c): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (c2): ConvBlock(\n        (c): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n        (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (se): SeBlock(\n        (globpool): AdaptiveAvgPool2d(output_size=(1, 1))\n        (fc1): Linear(in_features=576, out_features=24, bias=False)\n        (fc2): Linear(in_features=24, out_features=576, bias=False)\n        (silu): SiLU()\n        (sigmoid): Sigmoid()\n      )\n      (c3): ConvBlock(\n        (c): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): Identity()\n      )\n      (sd): StochasticDepth()\n    )\n    (9): MBConv(\n      (c1): ConvBlock(\n        (c): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (c2): ConvBlock(\n        (c): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n        (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (se): SeBlock(\n        (globpool): AdaptiveAvgPool2d(output_size=(1, 1))\n        (fc1): Linear(in_features=576, out_features=24, bias=False)\n        (fc2): Linear(in_features=24, out_features=576, bias=False)\n        (silu): SiLU()\n        (sigmoid): Sigmoid()\n      )\n      (c3): ConvBlock(\n        (c): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): Identity()\n      )\n      (sd): StochasticDepth()\n    )\n    (10): MBConv(\n      (c1): ConvBlock(\n        (c): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (c2): ConvBlock(\n        (c): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n        (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (se): SeBlock(\n        (globpool): AdaptiveAvgPool2d(output_size=(1, 1))\n        (fc1): Linear(in_features=576, out_features=24, bias=False)\n        (fc2): Linear(in_features=24, out_features=576, bias=False)\n        (silu): SiLU()\n        (sigmoid): Sigmoid()\n      )\n      (c3): ConvBlock(\n        (c): Conv2d(576, 135, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(135, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): Identity()\n      )\n      (sd): StochasticDepth()\n    )\n    (11-13): 3 x MBConv(\n      (c1): ConvBlock(\n        (c): Conv2d(135, 810, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(810, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (c2): ConvBlock(\n        (c): Conv2d(810, 810, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=810, bias=False)\n        (bn): BatchNorm2d(810, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (se): SeBlock(\n        (globpool): AdaptiveAvgPool2d(output_size=(1, 1))\n        (fc1): Linear(in_features=810, out_features=33, bias=False)\n        (fc2): Linear(in_features=33, out_features=810, bias=False)\n        (silu): SiLU()\n        (sigmoid): Sigmoid()\n      )\n      (c3): ConvBlock(\n        (c): Conv2d(810, 135, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(135, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): Identity()\n      )\n      (sd): StochasticDepth()\n    )\n    (14): MBConv(\n      (c1): ConvBlock(\n        (c): Conv2d(135, 810, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(810, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (c2): ConvBlock(\n        (c): Conv2d(810, 810, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=810, bias=False)\n        (bn): BatchNorm2d(810, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (se): SeBlock(\n        (globpool): AdaptiveAvgPool2d(output_size=(1, 1))\n        (fc1): Linear(in_features=810, out_features=33, bias=False)\n        (fc2): Linear(in_features=33, out_features=810, bias=False)\n        (silu): SiLU()\n        (sigmoid): Sigmoid()\n      )\n      (c3): ConvBlock(\n        (c): Conv2d(810, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): Identity()\n      )\n      (sd): StochasticDepth()\n    )\n    (15-17): 3 x MBConv(\n      (c1): ConvBlock(\n        (c): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (c2): ConvBlock(\n        (c): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n        (bn): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (se): SeBlock(\n        (globpool): AdaptiveAvgPool2d(output_size=(1, 1))\n        (fc1): Linear(in_features=1392, out_features=58, bias=False)\n        (fc2): Linear(in_features=58, out_features=1392, bias=False)\n        (silu): SiLU()\n        (sigmoid): Sigmoid()\n      )\n      (c3): ConvBlock(\n        (c): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): Identity()\n      )\n      (sd): StochasticDepth()\n    )\n    (18): MBConv(\n      (c1): ConvBlock(\n        (c): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (c2): ConvBlock(\n        (c): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=1392, bias=False)\n        (bn): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (se): SeBlock(\n        (globpool): AdaptiveAvgPool2d(output_size=(1, 1))\n        (fc1): Linear(in_features=1392, out_features=58, bias=False)\n        (fc2): Linear(in_features=58, out_features=1392, bias=False)\n        (silu): SiLU()\n        (sigmoid): Sigmoid()\n      )\n      (c3): ConvBlock(\n        (c): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): Identity()\n      )\n      (sd): StochasticDepth()\n    )\n    (19): MBConv(\n      (c1): ConvBlock(\n        (c): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (c2): ConvBlock(\n        (c): Conv2d(1392, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1392, bias=False)\n        (bn): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (se): SeBlock(\n        (globpool): AdaptiveAvgPool2d(output_size=(1, 1))\n        (fc1): Linear(in_features=1392, out_features=58, bias=False)\n        (fc2): Linear(in_features=58, out_features=1392, bias=False)\n        (silu): SiLU()\n        (sigmoid): Sigmoid()\n      )\n      (c3): ConvBlock(\n        (c): Conv2d(1392, 387, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(387, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): Identity()\n      )\n      (sd): StochasticDepth()\n    )\n    (20): ConvBlock(\n      (c): Conv2d(387, 1548, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(1548, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (silu): SiLU()\n    )\n    (21): Classifier(\n      (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n      (fc): Linear(in_features=1548, out_features=25, bias=True)\n      (dropout): Dropout(p=0.3, inplace=False)\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-08-08T09:25:16.314942Z","iopub.execute_input":"2024-08-08T09:25:16.315814Z","iopub.status.idle":"2024-08-08T09:25:16.333057Z","shell.execute_reply.started":"2024-08-08T09:25:16.315783Z","shell.execute_reply":"2024-08-08T09:25:16.332272Z"},"trusted":true},"execution_count":80,"outputs":[{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"EfficientNet(\n  (net): ModuleList(\n    (0): ConvBlock(\n      (c): Conv2d(3, 38, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (silu): SiLU()\n    )\n    (1): MBConv(\n      (c1): Identity()\n      (c2): ConvBlock(\n        (c): Conv2d(38, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=38, bias=False)\n        (bn): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (se): SeBlock(\n        (globpool): AdaptiveAvgPool2d(output_size=(1, 1))\n        (fc1): Linear(in_features=38, out_features=9, bias=False)\n        (fc2): Linear(in_features=9, out_features=38, bias=False)\n        (silu): SiLU()\n        (sigmoid): Sigmoid()\n      )\n      (c3): ConvBlock(\n        (c): Conv2d(38, 19, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): Identity()\n      )\n      (sd): StochasticDepth()\n    )\n    (2): MBConv(\n      (c1): ConvBlock(\n        (c): Conv2d(19, 114, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(114, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (c2): ConvBlock(\n        (c): Conv2d(114, 114, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=114, bias=False)\n        (bn): BatchNorm2d(114, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (se): SeBlock(\n        (globpool): AdaptiveAvgPool2d(output_size=(1, 1))\n        (fc1): Linear(in_features=114, out_features=4, bias=False)\n        (fc2): Linear(in_features=4, out_features=114, bias=False)\n        (silu): SiLU()\n        (sigmoid): Sigmoid()\n      )\n      (c3): ConvBlock(\n        (c): Conv2d(114, 29, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): Identity()\n      )\n      (sd): StochasticDepth()\n    )\n    (3): MBConv(\n      (c1): ConvBlock(\n        (c): Conv2d(29, 174, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(174, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (c2): ConvBlock(\n        (c): Conv2d(174, 174, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=174, bias=False)\n        (bn): BatchNorm2d(174, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (se): SeBlock(\n        (globpool): AdaptiveAvgPool2d(output_size=(1, 1))\n        (fc1): Linear(in_features=174, out_features=7, bias=False)\n        (fc2): Linear(in_features=7, out_features=174, bias=False)\n        (silu): SiLU()\n        (sigmoid): Sigmoid()\n      )\n      (c3): ConvBlock(\n        (c): Conv2d(174, 29, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): Identity()\n      )\n      (sd): StochasticDepth()\n    )\n    (4): MBConv(\n      (c1): ConvBlock(\n        (c): Conv2d(29, 174, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(174, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (c2): ConvBlock(\n        (c): Conv2d(174, 174, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=174, bias=False)\n        (bn): BatchNorm2d(174, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (se): SeBlock(\n        (globpool): AdaptiveAvgPool2d(output_size=(1, 1))\n        (fc1): Linear(in_features=174, out_features=7, bias=False)\n        (fc2): Linear(in_features=7, out_features=174, bias=False)\n        (silu): SiLU()\n        (sigmoid): Sigmoid()\n      )\n      (c3): ConvBlock(\n        (c): Conv2d(174, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): Identity()\n      )\n      (sd): StochasticDepth()\n    )\n    (5): MBConv(\n      (c1): ConvBlock(\n        (c): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (c2): ConvBlock(\n        (c): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n        (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (se): SeBlock(\n        (globpool): AdaptiveAvgPool2d(output_size=(1, 1))\n        (fc1): Linear(in_features=288, out_features=12, bias=False)\n        (fc2): Linear(in_features=12, out_features=288, bias=False)\n        (silu): SiLU()\n        (sigmoid): Sigmoid()\n      )\n      (c3): ConvBlock(\n        (c): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): Identity()\n      )\n      (sd): StochasticDepth()\n    )\n    (6): MBConv(\n      (c1): ConvBlock(\n        (c): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (c2): ConvBlock(\n        (c): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n        (bn): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (se): SeBlock(\n        (globpool): AdaptiveAvgPool2d(output_size=(1, 1))\n        (fc1): Linear(in_features=288, out_features=12, bias=False)\n        (fc2): Linear(in_features=12, out_features=288, bias=False)\n        (silu): SiLU()\n        (sigmoid): Sigmoid()\n      )\n      (c3): ConvBlock(\n        (c): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): Identity()\n      )\n      (sd): StochasticDepth()\n    )\n    (7-8): 2 x MBConv(\n      (c1): ConvBlock(\n        (c): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (c2): ConvBlock(\n        (c): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n        (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (se): SeBlock(\n        (globpool): AdaptiveAvgPool2d(output_size=(1, 1))\n        (fc1): Linear(in_features=576, out_features=24, bias=False)\n        (fc2): Linear(in_features=24, out_features=576, bias=False)\n        (silu): SiLU()\n        (sigmoid): Sigmoid()\n      )\n      (c3): ConvBlock(\n        (c): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): Identity()\n      )\n      (sd): StochasticDepth()\n    )\n    (9): MBConv(\n      (c1): ConvBlock(\n        (c): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (c2): ConvBlock(\n        (c): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n        (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (se): SeBlock(\n        (globpool): AdaptiveAvgPool2d(output_size=(1, 1))\n        (fc1): Linear(in_features=576, out_features=24, bias=False)\n        (fc2): Linear(in_features=24, out_features=576, bias=False)\n        (silu): SiLU()\n        (sigmoid): Sigmoid()\n      )\n      (c3): ConvBlock(\n        (c): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): Identity()\n      )\n      (sd): StochasticDepth()\n    )\n    (10): MBConv(\n      (c1): ConvBlock(\n        (c): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (c2): ConvBlock(\n        (c): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n        (bn): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (se): SeBlock(\n        (globpool): AdaptiveAvgPool2d(output_size=(1, 1))\n        (fc1): Linear(in_features=576, out_features=24, bias=False)\n        (fc2): Linear(in_features=24, out_features=576, bias=False)\n        (silu): SiLU()\n        (sigmoid): Sigmoid()\n      )\n      (c3): ConvBlock(\n        (c): Conv2d(576, 135, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(135, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): Identity()\n      )\n      (sd): StochasticDepth()\n    )\n    (11-13): 3 x MBConv(\n      (c1): ConvBlock(\n        (c): Conv2d(135, 810, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(810, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (c2): ConvBlock(\n        (c): Conv2d(810, 810, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=810, bias=False)\n        (bn): BatchNorm2d(810, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (se): SeBlock(\n        (globpool): AdaptiveAvgPool2d(output_size=(1, 1))\n        (fc1): Linear(in_features=810, out_features=33, bias=False)\n        (fc2): Linear(in_features=33, out_features=810, bias=False)\n        (silu): SiLU()\n        (sigmoid): Sigmoid()\n      )\n      (c3): ConvBlock(\n        (c): Conv2d(810, 135, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(135, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): Identity()\n      )\n      (sd): StochasticDepth()\n    )\n    (14): MBConv(\n      (c1): ConvBlock(\n        (c): Conv2d(135, 810, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(810, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (c2): ConvBlock(\n        (c): Conv2d(810, 810, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=810, bias=False)\n        (bn): BatchNorm2d(810, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (se): SeBlock(\n        (globpool): AdaptiveAvgPool2d(output_size=(1, 1))\n        (fc1): Linear(in_features=810, out_features=33, bias=False)\n        (fc2): Linear(in_features=33, out_features=810, bias=False)\n        (silu): SiLU()\n        (sigmoid): Sigmoid()\n      )\n      (c3): ConvBlock(\n        (c): Conv2d(810, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): Identity()\n      )\n      (sd): StochasticDepth()\n    )\n    (15-17): 3 x MBConv(\n      (c1): ConvBlock(\n        (c): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (c2): ConvBlock(\n        (c): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n        (bn): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (se): SeBlock(\n        (globpool): AdaptiveAvgPool2d(output_size=(1, 1))\n        (fc1): Linear(in_features=1392, out_features=58, bias=False)\n        (fc2): Linear(in_features=58, out_features=1392, bias=False)\n        (silu): SiLU()\n        (sigmoid): Sigmoid()\n      )\n      (c3): ConvBlock(\n        (c): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): Identity()\n      )\n      (sd): StochasticDepth()\n    )\n    (18): MBConv(\n      (c1): ConvBlock(\n        (c): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (c2): ConvBlock(\n        (c): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=1392, bias=False)\n        (bn): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (se): SeBlock(\n        (globpool): AdaptiveAvgPool2d(output_size=(1, 1))\n        (fc1): Linear(in_features=1392, out_features=58, bias=False)\n        (fc2): Linear(in_features=58, out_features=1392, bias=False)\n        (silu): SiLU()\n        (sigmoid): Sigmoid()\n      )\n      (c3): ConvBlock(\n        (c): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): Identity()\n      )\n      (sd): StochasticDepth()\n    )\n    (19): MBConv(\n      (c1): ConvBlock(\n        (c): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (c2): ConvBlock(\n        (c): Conv2d(1392, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1392, bias=False)\n        (bn): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): SiLU()\n      )\n      (se): SeBlock(\n        (globpool): AdaptiveAvgPool2d(output_size=(1, 1))\n        (fc1): Linear(in_features=1392, out_features=58, bias=False)\n        (fc2): Linear(in_features=58, out_features=1392, bias=False)\n        (silu): SiLU()\n        (sigmoid): Sigmoid()\n      )\n      (c3): ConvBlock(\n        (c): Conv2d(1392, 387, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn): BatchNorm2d(387, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (silu): Identity()\n      )\n      (sd): StochasticDepth()\n    )\n    (20): ConvBlock(\n      (c): Conv2d(387, 1548, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(1548, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (silu): SiLU()\n    )\n    (21): Classifier(\n      (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n      (fc): Linear(in_features=1548, out_features=25, bias=True)\n      (dropout): Dropout(p=0.3, inplace=False)\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Training loop\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    with tqdm(total=len(trainloader), desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch') as pbar:\n        for inputs, labels in trainloader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            labels = labels.long()  # Convert labels to LongTensor\n\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n            pbar.set_postfix(loss=running_loss/(pbar.n+1))\n            pbar.update(1)\n    \n    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(trainloader)}\")\n\nprint(\"Training complete.\")","metadata":{"execution":{"iopub.status.busy":"2024-08-08T09:25:18.731048Z","iopub.execute_input":"2024-08-08T09:25:18.731882Z","iopub.status.idle":"2024-08-08T09:36:16.021472Z","shell.execute_reply.started":"2024-08-08T09:25:18.731850Z","shell.execute_reply":"2024-08-08T09:36:16.020110Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stderr","text":"Epoch 1/10: 100%|██████████| 266/266 [01:44<00:00,  2.55batch/s, loss=3.29]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10, Loss: 3.292560879449199\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/10: 100%|██████████| 266/266 [01:46<00:00,  2.49batch/s, loss=3.23]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/10, Loss: 3.231930148332639\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/10: 100%|██████████| 266/266 [01:47<00:00,  2.48batch/s, loss=3.23]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/10, Loss: 3.2269425885121623\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/10: 100%|██████████| 266/266 [01:47<00:00,  2.48batch/s, loss=3.23]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/10, Loss: 3.2272207315703083\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/10: 100%|██████████| 266/266 [01:47<00:00,  2.48batch/s, loss=3.23]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/10, Loss: 3.2265133803948425\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/10: 100%|██████████| 266/266 [01:46<00:00,  2.49batch/s, loss=3.23]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/10, Loss: 3.2275688791633548\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/10:  16%|█▌        | 43/266 [00:17<01:32,  2.41batch/s, loss=3.23]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[81], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 20\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39mrunning_loss\u001b[38;5;241m/\u001b[39m(pbar\u001b[38;5;241m.\u001b[39mn\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     22\u001b[0m pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"class AlexNet(nn.Module):\n    def __init__(self, num_classes=25):\n        super().__init__()\n        self.features_extraction = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),  \n            nn.ReLU(inplace=True),\n            nn.BatchNorm2d(64),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n              \n            \n            nn.Conv2d(64, 192, kernel_size=5, padding=2),  \n            nn.ReLU(inplace=True),\n            nn.BatchNorm2d(192),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            \n            \n            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm2d(384),\n            \n            nn.Conv2d(384, 256, kernel_size=3, padding=1),  \n            nn.ReLU(inplace=True),\n            nn.BatchNorm2d(256),\n            \n            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm2d(256),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n            nn.AdaptiveAvgPool2d((6, 6)),  \n        )\n        self.classifier = nn.Sequential(\n            nn.Dropout(0.1),\n            nn.Linear(256 * 6 * 6, 4096),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm1d(4096),\n            \n            nn.Dropout(0.1),\n            nn.Linear(4096, 4096),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm1d(4096),\n            \n            nn.Dropout(0.1),\n            nn.Linear(4096, 512),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm1d(512),\n            \n            nn.Linear(512, num_classes),\n        )\n\n    def forward(self, x):\n        x = self.features_extraction(x)\n        x = x.view(x.size(0), -1)\n        return self.classifier(x)\n    \n\nmodel=AlexNet()\n# model = nn.DataParallel(model, device_ids = [0,1]) # to use multipleGPU\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-08-08T08:51:39.892013Z","iopub.execute_input":"2024-08-08T08:51:39.892752Z","iopub.status.idle":"2024-08-08T08:51:40.478034Z","shell.execute_reply.started":"2024-08-08T08:51:39.892714Z","shell.execute_reply":"2024-08-08T08:51:40.477000Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"import torch\n\n\nmodel_config = \"B0\" # [\"B0\", \"B1\", \"B2\", \"B3\", \"B4\", \"B5\", \"B6\", \"B7\"] -> are available\nmodel = EfficientNet(model_config)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-08T08:33:35.884483Z","iopub.execute_input":"2024-08-08T08:33:35.885171Z","iopub.status.idle":"2024-08-08T08:33:36.292213Z","shell.execute_reply.started":"2024-08-08T08:33:35.885138Z","shell.execute_reply":"2024-08-08T08:33:36.291094Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"tensor([[ 0.0144, -0.0247,  0.0072, -0.0172, -0.0075,  0.0021,  0.0141,  0.0129,\n         -0.0070, -0.0119, -0.0115,  0.0161, -0.0154, -0.0110,  0.0213,  0.0036,\n         -0.0031, -0.0131, -0.0105, -0.0057, -0.0256, -0.0274,  0.0150, -0.0059,\n          0.0128]], grad_fn=<AddmmBackward0>)\n","output_type":"stream"}]}]}